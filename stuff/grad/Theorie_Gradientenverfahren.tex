\documentclass[a4paper, 11pt]{article}

\usepackage{tikz}
\usepackage{Pgfplots}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc}
\usepackage{float}

\begin{document}
\pgfplotsset{
  compat=1.8,
  colormap={whitered}{color(0cm)=(white); color(1cm)=(orange!75!red)}
}



\tableofcontents

\newpage
\section{Die Idee und der Zweck des Gradientenverfahrens}

Grundsätzlich ist das Gradientenverfahren ein Optimierungsverfahren, mit welchem mna das Minimum einer mehrdimensionalen Funktion errechnen kann. Der Gradient (${\nabla}f(x,y)$) einer Funktion \(f(x,y)\) zeigt, aus später gezeigten (HIER VERWEIS EINFÜGEN) Gründen, immer in die Richtung des steilsten Anstiegs, folglich zeigt -${\nabla}f(x,y)$ in die Richtung des stärksten Abstiegs. Das Gradientenverfahren macht sich dies zunutze und man wandert eine gewisse Dauer in diese Richtung, wie lange man in die errechnete Richtung wandert hängt auch davon ab, wie man z.B. die Schrittweite ermittelt, dazu später mehr.

In den folgenden Absätzen werde ich versuchen zwei verschiedene Arten des Gradientenverfahrens zu zeigen und zu erklären.

\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}
\addplot3[surf]
{x*y^2};
\addplot3[->] coordinates {(-1.5,-0.5,54) (-2.5,-3.5,-70)}; 
\addplot3[only marks] coordinates {(-2,-2,-8)};
\end{axis}
\end{tikzpicture}
\caption[Gradientenvektor Beispiel]
{Hier zu sehen ist -$\vec{\nabla}f(-2,-2)$ der Funktion $f(x,y)=x*y^2$}
\end{figure}

\section{Schrittweitenbestimmung mittels Gleichungssystem}
In diesem Abschnitt möchte ich zeigen, wie man relative einfach (zu nicht zu komplizierten Funktionen) mittels dem Gradientenverfahren ein Minimum findet.

\subsection{Der Ablauf}
\begin{enumerate}

      \item 
      Es wird ein beliebiger Startpunk $P=(x,y)$ ausgewählt.
      \item 
      Es wird die Ableitung der Funktion $f(x,y)$, also ${\nabla}f(x)$ gebildet. Sollte dieser Gradient bereits den Wert null haben sind wir bereits fertig und haben ein lokales Minimum.
      \item 
      Der Punkt $P$ wird in den Gradienten eingesetzt und der negative Wert berechnet, also $-{\nabla}f(x_{P},y_{P})$.
      \item
      Um eine neuen Punkt $P^{[n+1]}$ zu finden stellen wir nun folgende Gleichung auf: $P^{[n+1]} = P^{[n]} + \alpha_{[n]} * s^{[n]}$. Nun haben wir die Richtung in die optimiert werden muss gefunden ($s^{[n]}$ ($=-{\nabla}f(x_{P},y_{P})$)), jetzt muss noch entschieden werden wie weit wir in diese Richtung "wandern" ($\alpha^{[n]}$, liegt zwischen $0$ und $1$) (Hinweis: $n$ ist die aktuelle Iteration). \\\\
      In diesem Kapitel werden wir die genau richtige Schrittweite auf Anhieb berechnen, dafür werden schaun wir uns zuerst die obere Gleichung $P^{[n+1]} = P^{[n]} + \alpha_{[n]} * s^{[n]}$ an. Aus dieser kann man herauslesen: $x=P^{[n]}_{x} + \alpha_{[n]} * s^{[n]}_{x}$ und $y=P^{[n]}_{y} + \alpha_{[n]} * s^{[n]}_{y}$. Dieses $x$ und $y$ wird nun in $f$ eingesetzt und die daraus resultierende Funktion, welche nur noch von $\alpha$ abhängig ist abermals abgeleitet. \\
      Diese abgeleitete Funktion wird nun gleich null gesetzt und so das passende $\alpha$ errechnet. Diese Art ein $alpha$ zu errechnen kann zwar bei einfachen Funktionen recht effizient von statten gehen, bei sehr komplexen und hochdimensionalen Funktionen aber auch enorm kompliziert werden, im gegensatz zu der in so einem Fall etwas simpleren Schrittweitenbestimmung mittels Armijo-Bedingung.      
      \item
      Wenn man einen neuen Punkt gefunden hat wird bei Punkt 3 fortgesetzt. Da es oft einen großen Rechenaufwand erfordert das genaue Minimum zu finden wird das Verfahren meist beendet wenn der Gradient einen akzeptablen Wert erreicht hat (So kann man als Abbruchbedingung z.B. die stärke des Anstiegs in einem Punkt (also den Betrag des Gradienten) nehmen).
      
      \end{enumerate}
      
      \subsection{Beispiel}
      
      Zu minimierende Funktion: $f(x,y) = 3x^3+y^2-3xy-3x$, als Abbruchbedingung wählen wir $|{\nabla}f(x,y)| \leq 0.6$
      
\begin{enumerate}

	\item 
	Startpunkt $P=(1,1)$
	\item 
	Ableitung: ${\nabla}f(x,y)=
	\left( \begin{array}{c}
	6x-3y-3 \\ 
	2y-3x 
	\end{array} \right)
	$($\rightarrow$ Der Gradient)
	\item
	$-{\nabla}f(1,1) =
	\left( \begin{array}{c}
	6-3-3 \\ 
	2-3
	\end{array} \right)
	=
	\left( \begin{array}{c}
	0 \\ 
	-1
	\end{array} \right)
	$ ($\rightarrow$ Richtung des stärksten Abstiegs)
	
	\item
	Nun haben wir folgende Gleichung: $P^{[1]}=P^{[0]}+\alpha*-{\nabla}f(P^{[0]}_{x},P^{[0]}_{y})$ bzw. $P^{[1]}=\left( \begin{array}{c} 1 \\ 1 \end{array} \right) + \alpha * \left( \begin{array}{c} 0 \\ -1 \end{array} \right)$. Das heißt unser $x=1$ und unser $y=1-\alpha$. Diese Werte werden nun in $f$ eingesetzt, sodass: $f(\alpha)=3+(1-\alpha)^2-3(1-\alpha)-3$ bzw. $f(\alpha)=(1-\alpha)^2-3(1-\alpha)$ und abgeleitet, also: $f'(\alpha)=3-2*(1-\alpha)$. Wenn wir die abgeleitete Funktion gleich null setzen und die daraus resultierende Gleichung lösen bekommen wir das optimale $\alpha = -0.5$. Nun haben wir ein passendes $\alpha$ gefunden und können zum nächsten Punkt wandern.
	
	\item
	 $P^{[1]}=\left( \begin{array}{c} 1 \\ 1 \end{array} \right) -0.5 * \left( \begin{array}{c} 0 \\ -1 \end{array} \right) = \left( \begin{array}{c} 1 \\ 1.5 \end{array} \right)$
	 
	 \item
	$-{\nabla}f(1,1.5) = \left( \begin{array}{c} 1.5 \\  0 \end{array} \right)$
	
	\item
	$P^{[2]}=\left( \begin{array}{c} 1 \\ 1.5 \end{array} \right) + \alpha * \left( \begin{array}{c} 1.5 \\ 0 \end{array} \right)$\\ $\rightarrow$ $x=1+1.5\alpha, y=1.5$\\ $\rightarrow$ $f(\alpha)=3(1+1.5\alpha)^2+1.5^2-4.5(1+1.5\alpha)-3(1+1.5\alpha)$\\ $\rightarrow$ $f'(\alpha)=\frac{54\alpha-9}{4}$\\ $\rightarrow$ $\alpha=\frac{1}{6}$
	
	\item
	$P^{[2]}=\left( \begin{array}{c} 1 \\ 1.5 \end{array} \right) + \frac{1}{6} * \left( \begin{array}{c} 1.5 \\ 0 \end{array} \right) = \left( \begin{array}{c} 1.25 \\ 1.5 \end{array} \right)$
	
	\item
	$-{\nabla}f(1.25,1.5) = \left( \begin{array}{c} 0 \\  0.75 \end{array} \right)$
	
	\item
	$P^{[3]}=\left( \begin{array}{c} 1.25 \\ 1.5 \end{array} \right) + \alpha * \left( \begin{array}{c}  0 \\ 0.75 \end{array} \right)$\\ $\rightarrow$ $x=1.25, y=1.5+0.75\alpha$\\ $\rightarrow$ $f(\alpha)=3*1.25^2+(1.5+0.75\alpha)^2-3.75(1.5+0.75\alpha)-3.75$\\ $\rightarrow$ $f'(\alpha)=\frac{18\alpha-9}{16}$\\ $\rightarrow$ $\alpha=0.5$
	
	\item
	$P^{[3]}=\left( \begin{array}{c} 1.25 \\ 1.5 \end{array} \right) +0.5 * \left( \begin{array}{c} 0 \\ 0.75 \end{array} \right) = \left( \begin{array}{c} 1.25 \\ 1.875 \end{array} \right)$
	
	\item
	$-{\nabla}f(1.25,1.875) = \left( \begin{array}{c} 1.125 \\ 0 \end{array} \right)$
	
	\item
	$P^{[4]}=\left( \begin{array}{c} 1.25 \\ 1.875 \end{array} \right) + \alpha * \left( \begin{array}{c}  1.125 \\ 0 \end{array} \right)$\\ $\rightarrow$ $x=1.25+1.125\alpha, y=1.875$\\ $\rightarrow$ $f(\alpha)=3*(1.25+1.125\alpha)^2+1.875^2-3*1.875*(1.25+1.125\alpha)-3*(1.25+1.125\alpha)$\\ $\rightarrow$ $f'(\alpha)=\frac{18\alpha-9}{16}$\\ $\rightarrow$ $\alpha=0.5$
	
	\item
	$P^{[4]}=\left( \begin{array}{c} 1.25 \\ 1.875 \end{array} \right) +0.5 * \left( \begin{array}{c} 1.125 \\ 0 \end{array} \right) = \left( \begin{array}{c} 1.438 \\ 1.875 \end{array} \right)$
	
	\item
	$-{\nabla}f(1.438,1.875) = \left( \begin{array}{c} 0 \\ 0.563 \end{array} \right)$
	
	\item
	Da $|{\nabla}f(1.438,1.875)| = \sqrt{0^2+0.563^2} = 0.563$ und $0.563 < 0.6$ haben wir einen Punkt gefunden, welcher nahe genug am Optimum liegt. \\
      
\end{enumerate}

\section{Schrittweitenbestimmung mittels der Armijo-Bedingung}
\subsection{Der Ablauf}

\begin{enumerate}
      \item 
      Es wird ein beliebiger Startpunk $P=(x,y)$ ausgewählt.
      \item 
      Es wird die Ableitung der Funktion $f(x,y)$, also ${\nabla}f(x)$ gebildet. Sollte dieser Gradient bereits den Wert null haben sind wir bereits fertig und haben ein lokales Minimum.
      \item 
      Der Punkt $P$ wird in den Gradienten eingesetzt und der negative Wert berechnet, also $-{\nabla}f(x_{P},y_{P})$.
      \item
      Um eine neuen Punkt $P^{[n+1]}$ zu finden stellen wir nun folgende Gleichung auf: $P^{[n+1]} = P^{[n]} + \alpha_{[n]} * s^{[n]}$. Nun haben wir die Richtung in die optimiert werden muss gefunden ($s^{[n]}$ ($=-{\nabla}f(x_{P},y_{P})$)), jetzt muss noch entschieden werden wie weit wir in diese Richtung "wandern" ($\alpha^{[n]}$, liegt zwischen $0$ und $1$) (Hinweis: $n$ ist die aktuelle Iteration). \\\\
      Das kann man einerseits mit Hilfe eines fixen Werts machen, andererseits auch mit einer Folge (wie z.B $\frac{1}{\sqrt{n}}$) oder einer jedes mal neu errechneten Schrittweite. Zu beachten ist, dass die ausgewählte Folge auf jeden Fall divergent sein muss, da man sonst bis zu einer maximalen Entfernung "wandern" kann und die Wahrscheinlichkeit groß ist das Optimum nie zu erreichen. Sollte man jedes mal einen fixen Wert verliert man zwar den Aufwand für die Berechnung der  Schrittweite, jedoch ist die Wahrscheinlichkeit hoch, dass man viele Iterationen benötigt oder in einer endlosen Schleife festhängt. \\\\
      Es gibt verschieden Arten wie man die Schrittweite berechnen kann, im Folgenden werde ich die Schrittweitenbestimmung nach Armijo erklären. Dieses Verfahren ist eines der sogenannten "line-search" Verfahren, das von mir gezeigte ist jedoch kein exaktes line-search Verfahren sondern lediglich eine einfache Heuristik. \\\\
      \textbf{Die Armijo-Bedingung:} $\varphi(\alpha) \leq \varphi(0) + c * \alpha^{[n]} * \varphi(0)'$. \\\\
      Wobei $c$ eine Konstante zwischen null und eins ist und dazu dient das die Bedingung nicht zu restriktiv ist, $\varphi(\alpha) = f(P^{[n]} + \alpha^{[n]}s^{[n]})$ und $\varphi(0)' = {\nabla}f(P^{n}) * s^{[n]}$
      \item
      Für den Anfang wird $\alpha=1$ gewählt und errechnet ob die Armijo-Bedingung erfüllt ist - sollte sie erfüllt sein haben wir ein passende $\alpha$ gefunden, wenn nicht wird $\alpha$ mit einem $\beta$, welches ebenfalls zwischen null und eins liegt, multipliziert und wieder geprüft ob die Ungleichung erfüllt ist. (Hinweis: In der Praxis liefern die Werte $c = 0.01$ und $\beta = 0.9$ häufig gute Ergebnisse. (QUELLE: https://www.unibw.de/lrt1/gerdts/lehre/lpnlp/lp-nlp.pdf)
      \item
      Wenn man einen neuen Punkt gefunden hat wird bei Punkt 3 fortgesetzt.
      
      
\end{enumerate}

\subsection{Beispiel}

Zu minimierende Funktion: $f(x,y)=y^4+2x^2-3xy+1$, als Abbruchbedingung wählen wir $|{\nabla}f(x,y)| \leq 0.3$
\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[
	scale=2,
    3d box,
    enlargelimits=false,
    grid=major,
    samples=21,
    domain=0.2:1.1,
    view={15}{30},
    xlabel={$x$},
    ylabel={$y$}
]
\addplot3[surf]
{ y^4+2*x^2-3*x*y+1 };
\addplot3 [contour gnuplot = {number=20, labels={false}, draw color=black},
        samples=21,z filter/.code={\def\pgfmathresult{3}}]
        {y^4+2*x^2-3*x*y+1};
\addplot3 [contour gnuplot = {number=20, labels={false}, draw color=black},
        samples=21]
        {y^4+2*x^2-3*x*y+1};
\node[label={180:{$P^{[1]}$}},circle,fill,inner sep=2pt] at (axis cs:1,1,1) {};
\node[label={180:{$P^{[2]}$}},circle,fill,inner sep=2pt] at (axis cs:0.41,0.41,0.86) {};
\node[label={180:{$P^{[3]}$}},circle,fill,inner sep=2pt] at (axis cs:0.308,0.648,0.767) {};
\node[label={180:{$P^{[4]}$}},circle,fill,inner sep=2pt] at (axis cs:0.486,0.607,0.723) {};
\node[label={180:{$P^{[5]}$}},circle,fill,inner sep=2pt] at (axis cs:0.455,0.748,0.706) {};
\node[label={180:{$P^{[1]}$}},circle,fill,inner sep=2pt] at (axis cs:1,1,3) {};
\addplot3[->, line width=2pt] coordinates {(1,1,3) (0.41,0.41,3)}; 
\node[label={180:{$P^{[2]}$}},circle,fill,inner sep=2pt] at (axis cs:0.41,0.41,3) {};
\addplot3[->, line width=2pt] coordinates {(0.41,0.41,3) (0.308,0.648,3)}; 
\node[label={180:{$P^{[3]}$}},circle,fill,inner sep=2pt] at (axis cs:0.308,0.648,3) {};
\addplot3[->, line width=2pt] coordinates {(0.308,0.648,3) (0.486,0.607,3)}; 
\node[label={180:{$P^{[4]}$}},circle,fill,inner sep=2pt] at (axis cs:0.486,0.607,3) {};
\addplot3[->, line width=2pt] coordinates {(0.486,0.607,3) (0.455,0.748,3)}; 
\node[label={180:{$P^{[5]}$}},circle,fill,inner sep=2pt] at (axis cs:0.455,0.748,3) {};
\end{axis}
\end{tikzpicture}
\caption[Zweidimensionale Funktion für Beispiel 2]
{Hier zu sehen ist die Zweidimensionale Funktion, die bei der Angabe von Beispiel 2 gegeben ist. Zusätzlich sind hier die Höhenschichtlinien eingezeichnet. Wie man sieht nähert man sich mit jeder Iteration an das Optimum der Funktion an.}
\end{figure}


\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[
    3d box,
    enlargelimits=false,
    grid=major,
    samples=21,
    domain=0.2:1.1,
    view={0}{90},
    xlabel={$x$},
    ylabel={$y$},
    scale=2
]
\addplot3 [contour gnuplot = {number=100, labels={false}, draw color=black},
        samples=21,z filter/.code={\def\pgfmathresult{0}}]
        {y^4+2*x^2-3*x*y+1};
\node[label={180:{$P^{[1]}$}},circle,fill,inner sep=2pt] at (axis cs:1,1,0) {};
\addplot3[->, line width=2pt] coordinates {(1,1,0) (0.41,0.41,0)}; 
\node[label={180:{$P^{[2]}$}},circle,fill,inner sep=2pt] at (axis cs:0.41,0.41,0) {};
\addplot3[->, line width=2pt] coordinates {(0.41,0.41,0) (0.308,0.648,0)}; 
\node[label={180:{$P^{[3]}$}},circle,fill,inner sep=2pt] at (axis cs:0.308,0.648,0) {};
\addplot3[->, line width=2pt] coordinates {(0.308,0.648,0) (0.486,0.607,0)}; 
\node[label={180:{$P^{[4]}$}},circle,fill,inner sep=2pt] at (axis cs:0.486,0.607,0) {};
\addplot3[->, line width=2pt] coordinates {(0.486,0.607,0) (0.455,0.748,0)}; 
\node[label={180:{$P^{[5]}$}},circle,fill,inner sep=2pt] at (axis cs:0.455,0.748,0) {};
\end{axis}
\end{tikzpicture}
\caption[Höhenlinien der zweidimensionale Funktion für Beispiel 1]
{Hier zu sehen sind die Höhenlinien der Funktion bei Beispiel 1. Wie man sieht nähert man sich mit jeder Iteration an das Optimum der Funktion an.}
\end{figure}

\begin{enumerate}
	\item 
	Startpunkt $P=(1,1)$
	\item 
	Ableitung: ${\nabla}f(x,y)=
	\left( \begin{array}{c}
	4x-3y \\ 
	4y^3-3x 
	\end{array} \right)
	$($\rightarrow$ Der Gradient)
	\item
	$-{\nabla}f(1,1) =
	\left( \begin{array}{c}
	-4+3 \\ 
	-4+3 
	\end{array} \right)
	=
	\left( \begin{array}{c}
	-1 \\ 
	-1
	\end{array} \right)
	$ ($\rightarrow$ Richtung des stärksten Abstiegs)
	\item
	Die Armijo-Bedingung (mit $\alpha = 1$, $c = 0.1$ und $\beta = 0.9$):\\
	$f( \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 1 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)) \leq f(\left( \begin{array}{c} 1 \\ 1 \end{array} \right)) + 0.1 * 1 *  \left( \begin{array}{c} 1 \\ 1 \end{array} \right) * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)$ \\
	$= 1 \leq 0.8$ \\
	$\rightarrow \alpha^{[2]} = \alpha^{[1]} * \beta = 0.9$ \\
	
	$f( \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 0.9 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)) \leq f(\left( \begin{array}{c} 1 \\ 1 \end{array} \right)) + 0.1 * 0.9 *  \left( \begin{array}{c} 1 \\ 1 \end{array} \right) * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)$ \\
	$= 0.99 \leq 0.82$ \\
	$\rightarrow \alpha^{[3]} = \alpha^{[2]} * \beta = 0.81$ \\
	
	$f( \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 0.81 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)) \leq f(\left( \begin{array}{c} 1 \\ 1 \end{array} \right)) + 0.1 * 0.81 *  \left( \begin{array}{c} 1 \\ 1 \end{array} \right) * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)$ \\
	$= 0.965 \leq 0.838$ \\
	$\rightarrow \alpha^{[4]} = \alpha^{[3]} * \beta = 0.729$ \\
	
	$f( \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 0.729 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)) \leq f(\left( \begin{array}{c} 1 \\ 1 \end{array} \right)) + 0.1 * 0.729 *  \left( \begin{array}{c} 1 \\ 1 \end{array} \right) * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)$ \\
	$= 0.932 \leq 0.854$ \\
	$\rightarrow \alpha^{[5]} = \alpha^{[4]} * \beta = 0.656$ \\
	
	$f( \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 0.656 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)) \leq f(\left( \begin{array}{c} 1 \\ 1 \end{array} \right)) + 0.1 * 0.656 *  \left( \begin{array}{c} 1 \\ 1 \end{array} \right) * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)$ \\
	$= 0.896 \leq 0.869$ \\
	$\rightarrow \alpha^{[6]} = \alpha^{[5]} * \beta = 0,59$ \\
	
	$f( \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 0,59 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)) \leq f(\left( \begin{array}{c} 1 \\ 1 \end{array} \right)) + 0.1 * 0,59 *  \left( \begin{array}{c} 1 \\ 1 \end{array} \right) * \left( \begin{array}{c} -1 \\ -1 \end{array} \right)$ \\
	$= 0.86 \leq 0.882$ \\
	Nun haben wir ein passendes $\alpha$ gefunden und können zum nächsten Punkt wandern.
	
	\begin{figure}
\centering
\begin{tikzpicture}
\begin{axis}[
	grid=major,
	domain=0:1,
	ymin=0.6,
    ymax=1.2,
    xlabel={$\alpha$},
    ylabel={$\varphi(\alpha)$},
    scale=2
]
\addplot[]
{ (1-x)^4+2*(1-x)^2-3*(1-x)*(1-x)+1 } node[above,pos=0.4] {$\varphi(\alpha)$};
\addplot[color=red]
{ (1^4+2*1^2-3*1*1+1) + x * (-2)} node[at=(current axis.left of origin), anchor=west, pos=0.15] {$\varphi(0) + \alpha^{[n]} * \varphi(0)'$};
\addplot[color=blue]
{ (1^4+2*1^2-3*1*1+1) + 0.1 * x * (-2)} node[at=(current axis.left of origin), anchor=south, pos=0.3, yshift=15pt] {$\varphi(0) +  c * \alpha^{[n]} * \varphi(0)'$};

\node[label={180:{$\alpha=0.59$}},circle,fill,inner sep=2pt] at (axis cs:0.59,0.86) {};
\node[label={180:{$\alpha=0.656$}},circle,fill,inner sep=2pt] at (axis cs:0.656,0.896,0) {};
\node[label={180:{$\alpha=0.729$}},circle,fill,inner sep=2pt] at (axis cs:0.729,0.932,0) {};
\node[label={180:{$\alpha=0.81$}},circle,fill,inner sep=2pt] at (axis cs:0.81,0.965) {};
\node[label={180:{$\alpha=0.9$}},circle,fill,inner sep=2pt] at (axis cs:0.9,0.99) {};
\node[label={180:{$\alpha=1$}},circle,fill,inner sep=2pt] at (axis cs:1,1,0) {};

\end{axis}
\end{tikzpicture}
\caption[Die Armijo-Bedingung]
{Hier sieht man die Funktion $\varphi(\alpha)=(1-\alpha)^4+2*(1-\alpha)^2-3*(1-\alpha)*(1-\alpha)+1)$, sie ist sozusagen ein Durchschnitt durch die bei Beispiel 1 gegebene Funktion. Diese Funktion wird erzeugt, wenn man vom Punkt $P^{[1]}=(1,1)$ in Richtung des Gradienten wandert. Die blaue Gerade zeigt die Armijo-Bedingung bei $c=0.1$, die rote bei $c=1$ bzw. ohne c.}
\end{figure}

    \item
    $P^{[2]} = \left( \begin{array}{c} 1 \\ 1 \end{array} \right) + 0,59 * \left( \begin{array}{c} -1 \\ -1 \end{array} \right) = \left( \begin{array}{c} 0.41 \\ 0.41 \end{array} \right)$
    \item
    $-{\nabla}f(0.41,0.41) = \left( \begin{array}{c} -0.41 \\ 0.95 \end{array} \right)$, \\
	$|{\nabla}f(0.41,0.41)| = \sqrt{0.41^2+0.95^2} = 1.071$
	\item    
	Die Armijo-Bedingung (mit $\alpha = 1$, $c = 0.1$ und $\beta = 0.5$):\\
	$f( \left( \begin{array}{c} 0.41 \\ 0.41 \end{array} \right) + 1 * \left( \begin{array}{c} -0.41 \\ 0.95 \end{array} \right)) \leq f(\left( \begin{array}{c} 0.41 \\ 0.41 \end{array} \right)) + 0.1 * 1 *  \left( \begin{array}{c} -0.41 \\ 0.95 \end{array} \right) * \left( \begin{array}{c} 0.41 \\ -0.95 \end{array} \right)$ \\
	$= 4.421 \leq 0.753$
	$\rightarrow \alpha^{[2]} = \alpha^{[1]} * \beta = 0.5$ \\
	$\rightarrow = 1.153 \leq 0.807$
	$\rightarrow \alpha^{[3]} = \alpha^{[2]} * \beta = 0.25$ \\
	$\rightarrow = 0.768 \leq 0.833$
	\item
	$P^{[3]} = \left( \begin{array}{c} 0.41 \\ 0.41 \end{array} \right) + 0.25 * \left( \begin{array}{c} -0.41 \\ 0.95 \end{array} \right) = \left( \begin{array}{c} 0.308 \\ 0.648 \end{array} \right)$
	\item
	$-{\nabla}f(0.308,0.648) = \left( \begin{array}{c} 0.712 \\ -0.164 \end{array} \right)$, \\
	$|{\nabla}f(0.308,0.648)| = \sqrt{0.712^2+0.164^2} = 0.534$
	\item
	Die Armijo-Bedingung (mit $\alpha = 1$, $c = 0.1$ und $\beta = 0.5$):\\
	$f( \left( \begin{array}{c} 0.308 \\ 0.648 \end{array} \right) + 1 * \left( \begin{array}{c} 0.712 \\ -0.164 \end{array} \right)) \leq f(\left( \begin{array}{c} 0.308 \\ 0.648 \end{array} \right)) + 0.1 * 1 *  \left( \begin{array}{c} 0.712 \\ -0.164 \end{array} \right) * \left( \begin{array}{c} -0.712 \\ 0.164 \end{array} \right)$ \\
	$= 1.655 \leq 0.714$
	$\rightarrow \alpha^{[2]} = \alpha^{[1]} * \beta = 0.5$ \\
	$\rightarrow = 0.857 \leq 0.741$
	$\rightarrow \alpha^{[3]} = \alpha^{[2]} * \beta = 0.25$ \\
	$\rightarrow = 0.723 \leq 0.754$
	\item
	$P^{[4]} = \left( \begin{array}{c} 0.308 \\ 0.648 \end{array} \right) + 0.25 * \left( \begin{array}{c} 0.712 \\ -0.164 \end{array} \right) = \left( \begin{array}{c} 0.486 \\ 0.607 \end{array} \right)$
	\item
	$-{\nabla}f(0.486,0.607) = \left( \begin{array}{c} -0.123 \\ 0.563. \end{array} \right)$, \\
	$|{\nabla}f(0.486,0.607)| = \sqrt{0.123^2+0.563^2} = 0.332$ 
	\item
	Die Armijo-Bedingung (mit $\alpha = 1$, $c = 0.1$ und $\beta = 0.5$):\\
	$f( \left( \begin{array}{c} 0.486 \\ 0.607 \end{array} \right) + 1 * \left( \begin{array}{c} -0.123 \\ 0.563 \end{array} \right)) \leq f(\left( \begin{array}{c} 0.486 \\ 0.607 \end{array} \right)) + 0.1 * 1 *  \left( \begin{array}{c} -0.123 \\ 0.563 \end{array} \right) * \left( \begin{array}{c} 0.123 \\ -0.563 \end{array} \right)$ \\
	$= 1.863 \leq 0.689$
	$\rightarrow \alpha^{[2]} = \alpha^{[1]} * \beta = 0.5$ \\
	$\rightarrow = 0.852 \leq 0.707$
	$\rightarrow \alpha^{[3]} = \alpha^{[2]} * \beta = 0.25$ \\
	$\rightarrow = 0.706 \leq 0.715$
	\item
	$P^{[5]} = \left( \begin{array}{c} 0.486 \\ 0.607 \end{array} \right) + 0.25 * \left( \begin{array}{c} -0.123 \\ 0.563 \end{array} \right) = \left( \begin{array}{c} 0.455 \\ 0.748 \end{array} \right)$
    \item
	$-{\nabla}f(0.455,0.748) = \left( \begin{array}{c} 0.424 \\ -0.309. \end{array} \right)$, \\
	$|{\nabla}f(0.455,0.748)| = \sqrt{0.424^2+0.309^2} = 0.275$ \\
	Die Abbruchbedingung ist erfüllt und somit ist ein Punkt, welcher nahe genug am Optimum liegt gefunden.
	
	
\end{enumerate}


\end{document}