<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Nichtlineare Optimierung ohne Nebenbedingungen: Mehrdimensionale Verfahren</title>
  

  <link rel="shortcut icon" href="./img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="./css/theme.css" type="text/css" />
  <link rel="stylesheet" href="./css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="./css/highlight.css">

  
  <script>
    // Current page data
    var mkdocs_page_name = "None";
  </script>
  
  <script src="./js/jquery-2.1.1.min.js"></script>
  <script src="./js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="./js/highlight.pack.js"></script>
  <script src="./js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> Nichtlineare Optimierung ohne Nebenbedingungen: Mehrdimensionale Verfahren</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href=".">Home</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#nelder-mead-verfahren">Nelder-Mead-Verfahren</a></li>
                
            
                <li class="toctree-l3"><a href="#abstiegsverfahren">Abstiegsverfahren</a></li>
                
            
                <li class="toctree-l3"><a href="#gradientenverfahren">Gradientenverfahren</a></li>
                
            
                <li class="toctree-l3"><a href="#koordinatenabstiegsmethode">Koordinatenabstiegsmethode</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="nmo/">Nelder-Mead Verfahren</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="gradienten/">Gradientenverfahren</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="koordinatenabstieg/">Koordinatenabstiegsmethode</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">Nichtlineare Optimierung ohne Nebenbedingungen: Mehrdimensionale Verfahren</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>Home</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="nelder-mead-verfahren">Nelder-Mead-Verfahren</h2>
<p>Das Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabhängige Punkte gewählt werden (also ein Simplex gebildet wird) aus denen der „schlechteste“ Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch nähert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen Fällen auf lokale Nebenoptima konvergieren kann. Hierfür gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu lösen.</p>
<h2 id="abstiegsverfahren">Abstiegsverfahren</h2>
<p>Das Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d heißt Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt: <code>f (x + td) &lt; f (x)</code> für jedes <code>0 &lt; t &lt; T</code>. Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir können auch sagen, dass wenn <code>∇f (x)T d &lt; 0</code> gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.</p>
<h2 id="gradientenverfahren">Gradientenverfahren</h2>
<p>Grundsätzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des stärksten Anstiegs zeigt. Dementsprechend zeigt natürlich der negative Gradient in die Richtung des stärksten Abstiegs. Nun „geht“ man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl stärker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.</p>
<h2 id="koordinatenabstiegsmethode">Koordinatenabstiegsmethode</h2>
<p>Bei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gewählt, nach der optimiert wird. Der Startpunkt ist beliebig wählbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gewählte Koordinate i behält man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum verändert; danach wird abgebrochen.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="nmo/" class="btn btn-neutral float-right" title="Nelder-Mead Verfahren"/>Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
        <span style="margin-left: 15px"><a href="nmo/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>

<!--
MkDocs version : 0.14.0
Build Date UTC : 2016-01-28 13:26:59.688691
-->
