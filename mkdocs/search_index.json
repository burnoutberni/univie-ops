{
    "docs": [
        {
            "location": "/",
            "text": "Nelder-Mead-Verfahren\n\n\nDas Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabh\u00e4ngige Punkte gew\u00e4hlt werden (also ein Simplex gebildet wird) aus denen der \u201eschlechteste\u201c Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch n\u00e4hert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen F\u00e4llen auf lokale Nebenoptima konvergieren kann. Hierf\u00fcr gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu l\u00f6sen.\n\n\nAbstiegsverfahren\n\n\nDas Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d hei\u00dft Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt: \nf (x + td) < f (x)\n f\u00fcr jedes \n0 < t < T\n. Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir k\u00f6nnen auch sagen, dass wenn \n\u2207f (x)T d < 0\n gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.\n\n\nGradientenverfahren\n\n\nGrunds\u00e4tzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des st\u00e4rksten Anstiegs zeigt. Dementsprechend zeigt nat\u00fcrlich der negative Gradient in die Richtung des st\u00e4rksten Abstiegs. Nun \u201egeht\u201c man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl st\u00e4rker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.\n\n\nKoordinatenabstiegsmethode\n\n\nBei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gew\u00e4hlt, nach der optimiert wird. Der Startpunkt ist beliebig w\u00e4hlbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gew\u00e4hlte Koordinate i beh\u00e4lt man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum ver\u00e4ndert; danach wird abgebrochen.",
            "title": "Home"
        },
        {
            "location": "/#nelder-mead-verfahren",
            "text": "Das Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabh\u00e4ngige Punkte gew\u00e4hlt werden (also ein Simplex gebildet wird) aus denen der \u201eschlechteste\u201c Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch n\u00e4hert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen F\u00e4llen auf lokale Nebenoptima konvergieren kann. Hierf\u00fcr gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu l\u00f6sen.",
            "title": "Nelder-Mead-Verfahren"
        },
        {
            "location": "/#abstiegsverfahren",
            "text": "Das Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d hei\u00dft Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt:  f (x + td) < f (x)  f\u00fcr jedes  0 < t < T . Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir k\u00f6nnen auch sagen, dass wenn  \u2207f (x)T d < 0  gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.",
            "title": "Abstiegsverfahren"
        },
        {
            "location": "/#gradientenverfahren",
            "text": "Grunds\u00e4tzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des st\u00e4rksten Anstiegs zeigt. Dementsprechend zeigt nat\u00fcrlich der negative Gradient in die Richtung des st\u00e4rksten Abstiegs. Nun \u201egeht\u201c man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl st\u00e4rker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.",
            "title": "Gradientenverfahren"
        },
        {
            "location": "/#koordinatenabstiegsmethode",
            "text": "Bei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gew\u00e4hlt, nach der optimiert wird. Der Startpunkt ist beliebig w\u00e4hlbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gew\u00e4hlte Koordinate i beh\u00e4lt man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum ver\u00e4ndert; danach wird abgebrochen.",
            "title": "Koordinatenabstiegsmethode"
        },
        {
            "location": "/nmo/",
            "text": "Einf\u00fchrung\n\n\nBeispiele\n\n\n\n\n\n\nImplementation\n\n\nKlassen\u00fcbersicht\n\n\nInstanzvariablen\n\n\n\n\n\n\n\n\nVariablenname\n\n\nBeschreibung\n\n\n\n\n\n\n\n\n\n\nFunktion& f\n\n\nzu optimierendes Funktionsobjekt\n\n\n\n\n\n\npoint b\n\n\nbester Simplexpunkt\n\n\n\n\n\n\npoint g\n\n\nmittlerer Simplexpunkt\n\n\n\n\n\n\npoint w\n\n\nschlechtester Simplexpunkt\n\n\n\n\n\n\ndouble eps\n\n\nEpsilon (Kovergenzkriterium)\n\n\n\n\n\n\ndouble alpha_\n\n\nReflexionsfaktor\n\n\n\n\n\n\ndouble gamma_\n\n\nExpansionsfaktor\n\n\n\n\n\n\ndouble beta_\n\n\nKontraktionsfaktor\n\n\n\n\n\n\ndouble delta_\n\n\nKomprimierungsfaktor\n\n\n\n\n\n\nbool done\n\n\nZustandsvariable\n\n\n\n\n\n\n\n\nMethoden\n\n\n\n\n\n\n\n\nMethode\n\n\nBeschreibung\n\n\n\n\n\n\n\n\n\n\n- point& min(point&, point&)\n\n\nreturniert den kleineren (per Funktionswert) der beiden Punkte\n\n\n\n\n\n\n- point& min(point&, point&, point&)\n\n\nreturniert den kleinsten (per Funktionswert) der drei Punkte\n\n\n\n\n\n\n- void sort_points_by_fvalue()\n\n\nsortiert die drei Werte B, G, W sodass \nf(B) <= f(G) <= f(W)\n\n\n\n\n\n\n- void do_step()\n\n\nf\u00fchrt einen Optimierungsschritt aus\n\n\n\n\n\n\n+ double alpha()\n\n\nreturniert Reflexionsfaktor\n\n\n\n\n\n\n+ double gamma()\n\n\nreturniert Expansionsfaktor\n\n\n\n\n\n\n+ double beta()\n\n\nreturniert Kontraktionsfaktor\n\n\n\n\n\n\n+ double delta()\n\n\nreturniert Komprimierungsfaktor\n\n\n\n\n\n\n+ void set_alpha(double)\n\n\nsetzt Reflexionsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ void set_gamma(double)\n\n\nsetzt Expansionsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ void set_beta(double)\n\n\nsetzt Kontraktionsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ void set_delta(double)\n\n\nsetzt Komprimierungsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ point get_best_point()\n\n\nreturniert besten Simplexpunkt\n\n\n\n\n\n\n+ std::tuple<point, point, point> retrieve_current_simplex()\n\n\nreturniert Tupel aller drei Simplexpunkte\n\n\n\n\n\n\n+ bool done()\n\n\nreturniert Zustandsvariable\n\n\n\n\n\n\n+ void step()\n\n\nf\u00fchrt Optimierungsschritt aus, sortiert Punkte und setzt ggf. Zustandsvariable\n\n\n\n\n\n\n\n\nAlgorithmus selbst\n\n\nDie Implementierung umfasst eine Optimiererklasse \nnelder_mead_optimizer\n, der bei\nder Instanziierung diverse Parameter \u00fcbergeben werden m\u00fcssen:\n\n\n\n\nEine von der Klasse \nFunktion\n abgeleitete Funktionsrepr\u00e4sentation, die die\n  Methode \nvalue(double, double)\n bzw. \noperator()(double, double)\n implementiert\n  haben muss\n\n\n3 Startpunkte \np1\n, \np2\n, \np3\n der Form (x, y), die den Startsimplex konstruieren\n\n\nEin Double-Wert \neps\n, der den zu verwendenden Epsilon-Wert angibt [optional,\n  defaultm\u00e4\u00dfig .00001]\n\n\nEin Double-Wert f\u00fcr den Reflexionsfaktor \nalpha\n [optional, defaultm\u00e4\u00dfig 1]\n\n\nEin Double-Wert f\u00fcr den Expansionsfaktor \ngamma\n [optional, defaultm\u00e4\u00dfig 2]\n\n\nEin Double-Wert f\u00fcr den Kontraktionsfaktor \nbeta\n [optional, defaultm\u00e4\u00dfig .5]\n\n\nEin Double-Wert f\u00fcr den Komprimierungsfaktor \ndelta\n [optional, defaultm\u00e4\u00dfig .5]\n\n\n\n\nAlle optionalen Werte k\u00f6nnen nachtr\u00e4glich mit dem entsprechenden Getter und\nSetter abgefragt und ge\u00e4ndert werden. Die Setter f\u00fcr die Verhaltensfaktoren\n\nalpha\n, \nbeta\n, \ngamma\n und \ndelta\n pr\u00fcfen die Sinnhaftigkeit der \u00fcbergebenen\nWerte und werfen eine Exception des Typs \ninvalid_value\n mit einer\nFehlermeldung sollten diese nicht stimmen.\n\n\nEin Minimalbeispiel zum Rauskopieren:\n\n\nnelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0005);\nnmo.optimize();\npoint min = nmo.get_best_point();\n\nstd::cout << \"The minimum is at \" << min.format() << \"!\\n\";\n\n\n\n\nVorhergehendes Beispiel instanziiert ein Optimiererobjekt \nnmo\n, das die\nFunktion \nfn\n optimieren soll, mit den Startpunkten (-1, -5), (8, 8) und (3,\n-8). Das Epsilon f\u00fcr die Abbruchbedingung wurde als .0005 gew\u00e4hlt. Danach wird\ndie \noptimize\n-Methode aufgerufen, die die Optimierung bis zum Erreichen des\nKonvergenzkriteriums durchf\u00fchrt. Anschlie\u00dfend kann der beste Punkt mittels\n\nget_best_point()\n abgerufen werden. Die \npoint\n-Klasse liegt der\nImplementierung bei und umfasst die wichtigsten Vektor-Operationen sowie einen\nextrem coolen Initialisiererlisten-Konstruktor, der die kurze Anschreibweise im\nKonstruktoraufruf erm\u00f6glicht. Weiters wichtig sind die \nformat\n- und\n\nraw\n-Methoden, die den Inhalt des Punktes jeweils in einen String gie\u00dfen.\n\nformat()\n ist zur sch\u00f6nen Ausgabe gedacht und \nraw()\n als Zwischenmedium zur\nWeitergabe des Punktes an externe Programme (wie etwa gnuplot).\n\n\nUm den Algorithmus m\u00f6glichst flexibel benutzen zu k\u00f6nnen, kann auch die Methode\n\nstep\n verwendet werden, um den Algorithmus schrittweise verfolgen zu k\u00f6nnen.\nAuskunft \u00fcber den Zustand gibt die \ndone\n Methode. Folgendes Beispiel optimiert\neine Funktion wie das vorige, gibt bei jedem Schritt jedoch auch den\nderzeitigen Simplex aus.\n\n\nnelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0005);\n\nsize_t n = 0;\nwhile(!nmo.done()) {\n    std::cout << \"\\nIteration #\" << n++ << '\\n';\n    auto points = nmo.retrieve_current_simplex();\n\n    std::cout << \"B = \" << std::get<0>(points).format() << '\\n'\n              << \"G = \" << std::get<1>(points).format() << '\\n'\n              << \"W = \" << std::get<2>(points).format() << '\\n';\n\n    nmo.step();\n}\n\n\n\n\nTestprogramm\n\n\nDas Testprogramm ben\u00f6tigt POSIX-Pipes (i.e. ist nur auf Linux und ggf. auch OS\nX lauff\u00e4hig) und gnuplot zum darstellen des Optimierungsverlaufes. Folgende\nFunktionen sind vorimplementiert:\n\n\n\n\nHimmelblau-Funktion (Befehl: \nhimmelblau\n)\n\n\nRosenbrocks Bananen-Funktion (Befehl: \nbanana\n)\n\n\nMatyas-Funktion (Befehl: \nmatyas\n)\n\n\nDreih\u00f6cker-Kamelfunktion (Befehl: \ncamel\n)\n\n\nBooth-Funktion (Befehl: \nbooth\n)\n\n\nBeale-Funktion (Befehl: \nbeale\n)\n\n\nBeispielfunktion 1, \n3*x**2 + y**2 - 3*x*y - 3*x\n (Befehl: \nexample1\n)\n\n\nBeispielfunktion 2, \ny**4 + 2*x**2 - 3*x*y + 1\n (Befehl: \nexample2\n)\n\n\nBeispielfunktion 3, \n3*x**2 + y + y**2\n (Befehl: \nexample3\n)\n\n\n\n\nEin Aufruf sieht folgenderma\u00dfen aus: \n./nelder_mead [FUNKTIONSNAME]\n. Per\ndefault schl\u00e4ft das Programm zwischen Iterationsschritten, um das betrachten\nder Ausgabegraphen zu erm\u00f6glichen. Ist dies nicht genug, kann via\n\n./nelder_mead [FUNKTIONSNAME] manual\n erwirkt werden, dass auf eine beliebige\nUsereingabe gewartet wird.\n\n\nWeiters ist eine kleine Informationsfunktion eingebaut. Mittels \n./nelder_mead\ninfo [FUNKTIONSNAME]\n kann diese aufgerufen werden und liefert dann\nbeispielsweise solche Ausgaben:\n\n\n$ ./nelder_mead info himmelblau\n\nH I M M E L B L A U  function\nThe Himmelblau function is commonly used for benchmarking optimization\nalgorithms. It is defined as\n                    2          2         2     2\n        f(x, y) = (x  + y - 11)  + (x + y  - 7)\n\nIts minima are at positions\n    f(3.2, 2.0) = 0.0\n    f(-2.805118, 3.131312) = 0.0\n    f(-3.779310, -3.283186) = 0.0\n    f(3.584428, -1.848126) = 0.0\n\n\n\n\nEs werden zumindest die Funktionsdefinition sowie die Minima ausgegeben.\n\n\nWerden dem Programm keine Argumente \u00fcbergeben, beschwert es sich\ndementsprechend und zeigt eine kleine Hilfe mit den unterst\u00fctzten\nFunktionalit\u00e4ten an. \u00dcbersch\u00fcssige Argumente werden ignoriert.",
            "title": "Nelder-Mead Verfahren"
        },
        {
            "location": "/nmo/#einfuhrung",
            "text": "",
            "title": "Einf\u00fchrung"
        },
        {
            "location": "/nmo/#beispiele",
            "text": "",
            "title": "Beispiele"
        },
        {
            "location": "/nmo/#implementation",
            "text": "Klassen\u00fcbersicht  Instanzvariablen     Variablenname  Beschreibung      Funktion& f  zu optimierendes Funktionsobjekt    point b  bester Simplexpunkt    point g  mittlerer Simplexpunkt    point w  schlechtester Simplexpunkt    double eps  Epsilon (Kovergenzkriterium)    double alpha_  Reflexionsfaktor    double gamma_  Expansionsfaktor    double beta_  Kontraktionsfaktor    double delta_  Komprimierungsfaktor    bool done  Zustandsvariable     Methoden     Methode  Beschreibung      - point& min(point&, point&)  returniert den kleineren (per Funktionswert) der beiden Punkte    - point& min(point&, point&, point&)  returniert den kleinsten (per Funktionswert) der drei Punkte    - void sort_points_by_fvalue()  sortiert die drei Werte B, G, W sodass  f(B) <= f(G) <= f(W)    - void do_step()  f\u00fchrt einen Optimierungsschritt aus    + double alpha()  returniert Reflexionsfaktor    + double gamma()  returniert Expansionsfaktor    + double beta()  returniert Kontraktionsfaktor    + double delta()  returniert Komprimierungsfaktor    + void set_alpha(double)  setzt Reflexionsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + void set_gamma(double)  setzt Expansionsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + void set_beta(double)  setzt Kontraktionsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + void set_delta(double)  setzt Komprimierungsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + point get_best_point()  returniert besten Simplexpunkt    + std::tuple<point, point, point> retrieve_current_simplex()  returniert Tupel aller drei Simplexpunkte    + bool done()  returniert Zustandsvariable    + void step()  f\u00fchrt Optimierungsschritt aus, sortiert Punkte und setzt ggf. Zustandsvariable     Algorithmus selbst  Die Implementierung umfasst eine Optimiererklasse  nelder_mead_optimizer , der bei\nder Instanziierung diverse Parameter \u00fcbergeben werden m\u00fcssen:   Eine von der Klasse  Funktion  abgeleitete Funktionsrepr\u00e4sentation, die die\n  Methode  value(double, double)  bzw.  operator()(double, double)  implementiert\n  haben muss  3 Startpunkte  p1 ,  p2 ,  p3  der Form (x, y), die den Startsimplex konstruieren  Ein Double-Wert  eps , der den zu verwendenden Epsilon-Wert angibt [optional,\n  defaultm\u00e4\u00dfig .00001]  Ein Double-Wert f\u00fcr den Reflexionsfaktor  alpha  [optional, defaultm\u00e4\u00dfig 1]  Ein Double-Wert f\u00fcr den Expansionsfaktor  gamma  [optional, defaultm\u00e4\u00dfig 2]  Ein Double-Wert f\u00fcr den Kontraktionsfaktor  beta  [optional, defaultm\u00e4\u00dfig .5]  Ein Double-Wert f\u00fcr den Komprimierungsfaktor  delta  [optional, defaultm\u00e4\u00dfig .5]   Alle optionalen Werte k\u00f6nnen nachtr\u00e4glich mit dem entsprechenden Getter und\nSetter abgefragt und ge\u00e4ndert werden. Die Setter f\u00fcr die Verhaltensfaktoren alpha ,  beta ,  gamma  und  delta  pr\u00fcfen die Sinnhaftigkeit der \u00fcbergebenen\nWerte und werfen eine Exception des Typs  invalid_value  mit einer\nFehlermeldung sollten diese nicht stimmen.  Ein Minimalbeispiel zum Rauskopieren:  nelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0005);\nnmo.optimize();\npoint min = nmo.get_best_point();\n\nstd::cout << \"The minimum is at \" << min.format() << \"!\\n\";  Vorhergehendes Beispiel instanziiert ein Optimiererobjekt  nmo , das die\nFunktion  fn  optimieren soll, mit den Startpunkten (-1, -5), (8, 8) und (3,\n-8). Das Epsilon f\u00fcr die Abbruchbedingung wurde als .0005 gew\u00e4hlt. Danach wird\ndie  optimize -Methode aufgerufen, die die Optimierung bis zum Erreichen des\nKonvergenzkriteriums durchf\u00fchrt. Anschlie\u00dfend kann der beste Punkt mittels get_best_point()  abgerufen werden. Die  point -Klasse liegt der\nImplementierung bei und umfasst die wichtigsten Vektor-Operationen sowie einen\nextrem coolen Initialisiererlisten-Konstruktor, der die kurze Anschreibweise im\nKonstruktoraufruf erm\u00f6glicht. Weiters wichtig sind die  format - und raw -Methoden, die den Inhalt des Punktes jeweils in einen String gie\u00dfen. format()  ist zur sch\u00f6nen Ausgabe gedacht und  raw()  als Zwischenmedium zur\nWeitergabe des Punktes an externe Programme (wie etwa gnuplot).  Um den Algorithmus m\u00f6glichst flexibel benutzen zu k\u00f6nnen, kann auch die Methode step  verwendet werden, um den Algorithmus schrittweise verfolgen zu k\u00f6nnen.\nAuskunft \u00fcber den Zustand gibt die  done  Methode. Folgendes Beispiel optimiert\neine Funktion wie das vorige, gibt bei jedem Schritt jedoch auch den\nderzeitigen Simplex aus.  nelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0005);\n\nsize_t n = 0;\nwhile(!nmo.done()) {\n    std::cout << \"\\nIteration #\" << n++ << '\\n';\n    auto points = nmo.retrieve_current_simplex();\n\n    std::cout << \"B = \" << std::get<0>(points).format() << '\\n'\n              << \"G = \" << std::get<1>(points).format() << '\\n'\n              << \"W = \" << std::get<2>(points).format() << '\\n';\n\n    nmo.step();\n}  Testprogramm  Das Testprogramm ben\u00f6tigt POSIX-Pipes (i.e. ist nur auf Linux und ggf. auch OS\nX lauff\u00e4hig) und gnuplot zum darstellen des Optimierungsverlaufes. Folgende\nFunktionen sind vorimplementiert:   Himmelblau-Funktion (Befehl:  himmelblau )  Rosenbrocks Bananen-Funktion (Befehl:  banana )  Matyas-Funktion (Befehl:  matyas )  Dreih\u00f6cker-Kamelfunktion (Befehl:  camel )  Booth-Funktion (Befehl:  booth )  Beale-Funktion (Befehl:  beale )  Beispielfunktion 1,  3*x**2 + y**2 - 3*x*y - 3*x  (Befehl:  example1 )  Beispielfunktion 2,  y**4 + 2*x**2 - 3*x*y + 1  (Befehl:  example2 )  Beispielfunktion 3,  3*x**2 + y + y**2  (Befehl:  example3 )   Ein Aufruf sieht folgenderma\u00dfen aus:  ./nelder_mead [FUNKTIONSNAME] . Per\ndefault schl\u00e4ft das Programm zwischen Iterationsschritten, um das betrachten\nder Ausgabegraphen zu erm\u00f6glichen. Ist dies nicht genug, kann via ./nelder_mead [FUNKTIONSNAME] manual  erwirkt werden, dass auf eine beliebige\nUsereingabe gewartet wird.  Weiters ist eine kleine Informationsfunktion eingebaut. Mittels  ./nelder_mead\ninfo [FUNKTIONSNAME]  kann diese aufgerufen werden und liefert dann\nbeispielsweise solche Ausgaben:  $ ./nelder_mead info himmelblau\n\nH I M M E L B L A U  function\nThe Himmelblau function is commonly used for benchmarking optimization\nalgorithms. It is defined as\n                    2          2         2     2\n        f(x, y) = (x  + y - 11)  + (x + y  - 7)\n\nIts minima are at positions\n    f(3.2, 2.0) = 0.0\n    f(-2.805118, 3.131312) = 0.0\n    f(-3.779310, -3.283186) = 0.0\n    f(3.584428, -1.848126) = 0.0  Es werden zumindest die Funktionsdefinition sowie die Minima ausgegeben.  Werden dem Programm keine Argumente \u00fcbergeben, beschwert es sich\ndementsprechend und zeigt eine kleine Hilfe mit den unterst\u00fctzten\nFunktionalit\u00e4ten an. \u00dcbersch\u00fcssige Argumente werden ignoriert.",
            "title": "Implementation"
        },
        {
            "location": "/abstieg/",
            "text": "",
            "title": "Abstiegsverfahren"
        },
        {
            "location": "/gradienten/",
            "text": "",
            "title": "Gradientenverfahren"
        },
        {
            "location": "/koordinatenabstieg/",
            "text": "",
            "title": "Koordinatenabstiegsmethode"
        }
    ]
}