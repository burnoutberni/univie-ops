{
    "docs": [
        {
            "location": "/",
            "text": "Nelder-Mead-Verfahren\n\n\nDas Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabh\u00e4ngige Punkte gew\u00e4hlt werden (also ein Simplex gebildet wird) aus denen der \u201eschlechteste\u201c Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch n\u00e4hert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen F\u00e4llen auf lokale Nebenoptima konvergieren kann. Hierf\u00fcr gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu l\u00f6sen.\n\n\nAbstiegsverfahren\n\n\nDas Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d hei\u00dft Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt: \nf (x + td) \n f (x)\n f\u00fcr jedes \n0 \n t \n T\n. Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir k\u00f6nnen auch sagen, dass wenn \n\u2207f (x)T d \n 0\n gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.\n\n\nGradientenverfahren\n\n\nGrunds\u00e4tzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des st\u00e4rksten Anstiegs zeigt. Dementsprechend zeigt nat\u00fcrlich der negative Gradient in die Richtung des st\u00e4rksten Abstiegs. Nun \u201egeht\u201c man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl st\u00e4rker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.\n\n\nKoordinatenabstiegsmethode\n\n\nBei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gew\u00e4hlt, nach der optimiert wird. Der Startpunkt ist beliebig w\u00e4hlbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gew\u00e4hlte Koordinate i beh\u00e4lt man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum ver\u00e4ndert; danach wird abgebrochen.",
            "title": "Home"
        },
        {
            "location": "/#nelder-mead-verfahren",
            "text": "Das Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabh\u00e4ngige Punkte gew\u00e4hlt werden (also ein Simplex gebildet wird) aus denen der \u201eschlechteste\u201c Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch n\u00e4hert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen F\u00e4llen auf lokale Nebenoptima konvergieren kann. Hierf\u00fcr gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu l\u00f6sen.",
            "title": "Nelder-Mead-Verfahren"
        },
        {
            "location": "/#abstiegsverfahren",
            "text": "Das Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d hei\u00dft Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt:  f (x + td)   f (x)  f\u00fcr jedes  0   t   T . Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir k\u00f6nnen auch sagen, dass wenn  \u2207f (x)T d   0  gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.",
            "title": "Abstiegsverfahren"
        },
        {
            "location": "/#gradientenverfahren",
            "text": "Grunds\u00e4tzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des st\u00e4rksten Anstiegs zeigt. Dementsprechend zeigt nat\u00fcrlich der negative Gradient in die Richtung des st\u00e4rksten Abstiegs. Nun \u201egeht\u201c man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl st\u00e4rker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.",
            "title": "Gradientenverfahren"
        },
        {
            "location": "/#koordinatenabstiegsmethode",
            "text": "Bei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gew\u00e4hlt, nach der optimiert wird. Der Startpunkt ist beliebig w\u00e4hlbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gew\u00e4hlte Koordinate i beh\u00e4lt man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum ver\u00e4ndert; danach wird abgebrochen.",
            "title": "Koordinatenabstiegsmethode"
        },
        {
            "location": "/nmo/",
            "text": "Einf\u00fchrung\n\n\nBeispiele\n\n\n\n\n\n\nImplementation\n\n\nKlassen\u00fcbersicht\n\n\nInstanzvariablen\n\n\n\n\n\n\n\n\nVariablenname\n\n\nBeschreibung\n\n\n\n\n\n\n\n\n\n\nFunktion\n f\n\n\nzu optimierendes Funktionsobjekt\n\n\n\n\n\n\npoint b\n\n\nbester Simplexpunkt\n\n\n\n\n\n\npoint g\n\n\nmittlerer Simplexpunkt\n\n\n\n\n\n\npoint w\n\n\nschlechtester Simplexpunkt\n\n\n\n\n\n\ndouble eps\n\n\nEpsilon (Kovergenzkriterium)\n\n\n\n\n\n\ndouble alpha_\n\n\nReflexionsfaktor\n\n\n\n\n\n\ndouble gamma_\n\n\nExpansionsfaktor\n\n\n\n\n\n\ndouble beta_\n\n\nKontraktionsfaktor\n\n\n\n\n\n\ndouble delta_\n\n\nKomprimierungsfaktor\n\n\n\n\n\n\nbool done\n\n\nZustandsvariable\n\n\n\n\n\n\nsize_t iter_c\n\n\nIterationsz\u00e4hler\n\n\n\n\n\n\n\n\nMethoden\n\n\n\n\n\n\n\n\nMethode\n\n\nBeschreibung\n\n\n\n\n\n\n\n\n\n\n- point\n min(point\n, point\n)\n\n\nreturniert den kleineren (per Funktionswert) der beiden Punkte\n\n\n\n\n\n\n- point\n min(point\n, point\n, point\n)\n\n\nreturniert den kleinsten (per Funktionswert) der drei Punkte\n\n\n\n\n\n\n- void sort_points_by_fvalue()\n\n\nsortiert die drei Werte B, G, W sodass \nf(B) \n= f(G) \n= f(W)\n\n\n\n\n\n\n- void do_step()\n\n\nf\u00fchrt einen Optimierungsschritt aus\n\n\n\n\n\n\n+ double alpha()\n\n\nreturniert Reflexionsfaktor\n\n\n\n\n\n\n+ double gamma()\n\n\nreturniert Expansionsfaktor\n\n\n\n\n\n\n+ double beta()\n\n\nreturniert Kontraktionsfaktor\n\n\n\n\n\n\n+ double delta()\n\n\nreturniert Komprimierungsfaktor\n\n\n\n\n\n\n+ void set_alpha(double)\n\n\nsetzt Reflexionsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ void set_gamma(double)\n\n\nsetzt Expansionsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ void set_beta(double)\n\n\nsetzt Kontraktionsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ void set_delta(double)\n\n\nsetzt Komprimierungsfaktor wenn m\u00f6glich, wirft sonst \ninvalid_value\n\n\n\n\n\n\n+ point best_point()\n\n\nreturniert besten Simplexpunkt\n\n\n\n\n\n\n+ std::tuple\npoint, point, point\n current_simplex()\n\n\nreturniert Tupel aller drei Simplexpunkte\n\n\n\n\n\n\n+ bool done()\n\n\nreturniert Zustandsvariable\n\n\n\n\n\n\n+ size_t iteration_count()\n\n\nreturniert den Wert des Iterationenz\u00e4hlers\n\n\n\n\n\n\n+ void step()\n\n\nf\u00fchrt Optimierungsschritt aus, sortiert Punkte und setzt ggf. Zustandsvariable\n\n\n\n\n\n\n+ optimize()\n\n\nf\u00fchrt die Optimierung die komplette Optimierung durch\n\n\n\n\n\n\n\n\nAlgorithmus selbst\n\n\nDie Implementierung umfasst eine Optimiererklasse \nnelder_mead_optimizer\n, der bei\nder Instanziierung diverse Parameter \u00fcbergeben werden m\u00fcssen:\n\n\n\n\nEine von der Klasse \nFunktion\n abgeleitete Funktionsrepr\u00e4sentation, die die\n  Methode \nvalue(double, double)\n bzw. \noperator()(double, double)\n implementiert\n  haben muss\n\n\n3 Startpunkte \np1\n, \np2\n, \np3\n der Form (x, y), die den Startsimplex konstruieren\n\n\nEin Double-Wert \neps\n, der den zu verwendenden Epsilon-Wert angibt [optional,\n  defaultm\u00e4\u00dfig .00001]\n\n\nEin Double-Wert f\u00fcr den Reflexionsfaktor \nalpha\n [optional, defaultm\u00e4\u00dfig 1]\n\n\nEin Double-Wert f\u00fcr den Expansionsfaktor \ngamma\n [optional, defaultm\u00e4\u00dfig 2]\n\n\nEin Double-Wert f\u00fcr den Kontraktionsfaktor \nbeta\n [optional, defaultm\u00e4\u00dfig .5]\n\n\nEin Double-Wert f\u00fcr den Komprimierungsfaktor \ndelta\n [optional, defaultm\u00e4\u00dfig .5]\n\n\n\n\nAlle optionalen Werte k\u00f6nnen nachtr\u00e4glich mit dem entsprechenden Getter und\nSetter abgefragt und ge\u00e4ndert werden. Die Setter f\u00fcr die Verhaltensfaktoren\n\nalpha\n, \nbeta\n, \ngamma\n und \ndelta\n pr\u00fcfen die Sinnhaftigkeit der \u00fcbergebenen\nWerte und werfen eine Exception des Typs \ninvalid_value\n mit einer\nFehlermeldung sollten diese nicht stimmen.\n\n\nEin Minimalbeispiel zum Rauskopieren (unter src/nmo/simple.cpp zu finden):\n\n\n#include \niostream\n\n#include \nnelder_mead_optimizer.hpp\n\n\nint main() {\n    struct : Funktion {\n        double value(double x, double y) { return x*x + y*y; }\n    } fn;\n\n    nelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0000001);\n    nmo.optimize();\n    point min = nmo.best_point();\n\n    std::cout \n \nThe minimum is at \n \n min.format() \n \n!\\nNeeded \n\n              \n nmo.iteration_count() \n \n iterations.\\n\n;\n\n\n\n\nVorhergehendes Beispiel instanziiert ein Optimiererobjekt \nnmo\n, das die\nFunktion \nfn\n optimieren soll, mit den Startpunkten (-1, -5), (8, 8) und (3,\n-8). Das Epsilon f\u00fcr die Abbruchbedingung wurde als .0005 gew\u00e4hlt. Danach wird\ndie \noptimize\n-Methode aufgerufen, die die Optimierung bis zum Erreichen des\nKonvergenzkriteriums durchf\u00fchrt. Anschlie\u00dfend kann der beste Punkt mittels\n\nget_best_point()\n abgerufen werden. Die \npoint\n-Klasse liegt der\nImplementierung bei und umfasst die wichtigsten Vektor-Operationen sowie einen\nextrem coolen Initialisiererlisten-Konstruktor, der die kurze Anschreibweise im\nKonstruktoraufruf erm\u00f6glicht. Weiters wichtig sind die \nformat\n- und\n\nraw\n-Methoden, die den Inhalt des Punktes jeweils in einen String gie\u00dfen.\n\nformat()\n ist zur sch\u00f6nen Ausgabe gedacht und \nraw()\n als Zwischenmedium zur\nWeitergabe des Punktes an externe Programme (wie etwa gnuplot).\n\n\nUm den Algorithmus m\u00f6glichst flexibel benutzen zu k\u00f6nnen, kann auch die Methode\n\nstep\n verwendet werden, um den Algorithmus schrittweise verfolgen zu k\u00f6nnen.\nAuskunft \u00fcber den Zustand gibt die \ndone\n Methode. Folgendes Beispiel optimiert\neine Funktion wie das vorige, gibt bei jedem Schritt jedoch auch den\nderzeitigen Simplex aus.\n\n\nnelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0005);\n\nwhile(!nmo.done()) {\n    std::cout \n \n\\nIteration #\n \n nmo.iteration_count() \n '\\n';\n    auto points = nmo.current_simplex();\n\n    std::cout \n \nB = \n \n std::get\n0\n(points).format() \n '\\n'\n              \n \nG = \n \n std::get\n1\n(points).format() \n '\\n'\n              \n \nW = \n \n std::get\n2\n(points).format() \n '\\n';\n\n    nmo.step();\n}\n\n\n\n\nTestprogramm\n\n\nDas Testprogramm ben\u00f6tigt POSIX-Pipes (i.e. ist nur auf Linux und ggf. auch OS\nX lauff\u00e4hig) und gnuplot zum darstellen des Optimierungsverlaufes. Folgende\nFunktionen sind vorimplementiert:\n\n\n\n\nHimmelblau-Funktion (Befehl: \nhimmelblau\n)\n\n\nRosenbrocks Bananen-Funktion (Befehl: \nbanana\n)\n\n\nMatyas-Funktion (Befehl: \nmatyas\n)\n\n\nDreih\u00f6cker-Kamelfunktion (Befehl: \ncamel\n)\n\n\nBooth-Funktion (Befehl: \nbooth\n)\n\n\nBeale-Funktion (Befehl: \nbeale\n)\n\n\nBeispielfunktion 1, \n3*x**2 + y**2 - 3*x*y - 3*x\n (Befehl: \nexample1\n)\n\n\nBeispielfunktion 2, \ny**4 + 2*x**2 - 3*x*y + 1\n (Befehl: \nexample2\n)\n\n\nBeispielfunktion 3, \n3*x**2 + y + y**2\n (Befehl: \nexample3\n)\n\n\n\n\nEin Aufruf sieht folgenderma\u00dfen aus: \n./nelder_mead [FUNKTIONSNAME]\n. Per\ndefault schl\u00e4ft das Programm zwischen Iterationsschritten, um das betrachten\nder Ausgabegraphen zu erm\u00f6glichen. Ist dies nicht genug, kann via\n\n./nelder_mead [FUNKTIONSNAME] manual\n erwirkt werden, dass auf eine beliebige\nUsereingabe gewartet wird.\n\n\nWeiters ist eine kleine Informationsfunktion eingebaut. Mittels \n./nelder_mead\ninfo [FUNKTIONSNAME]\n kann diese aufgerufen werden und liefert dann\nbeispielsweise solche Ausgaben:\n\n\n$ ./nelder_mead info himmelblau\n\nH I M M E L B L A U  function\nThe Himmelblau function is commonly used for benchmarking optimization\nalgorithms. It is defined as\n                    2          2         2     2\n        f(x, y) = (x  + y - 11)  + (x + y  - 7)\n\nIts minima are at positions\n    f(3.2, 2.0) = 0.0\n    f(-2.805118, 3.131312) = 0.0\n    f(-3.779310, -3.283186) = 0.0\n    f(3.584428, -1.848126) = 0.0\n\n\n\n\nEs werden zumindest die Funktionsdefinition sowie die Minima ausgegeben.\n\n\nWerden dem Programm keine Argumente \u00fcbergeben, beschwert es sich\ndementsprechend und zeigt eine kleine Hilfe mit den unterst\u00fctzten\nFunktionalit\u00e4ten an. \u00dcbersch\u00fcssige Argumente werden ignoriert.\n\n\nLinks\n\n\nFiles auf GitHub (garantiert aktuell)\n\n\nnelder_mead.zip",
            "title": "Nelder-Mead Verfahren"
        },
        {
            "location": "/nmo/#einfuhrung",
            "text": "",
            "title": "Einf\u00fchrung"
        },
        {
            "location": "/nmo/#beispiele",
            "text": "",
            "title": "Beispiele"
        },
        {
            "location": "/nmo/#implementation",
            "text": "Klassen\u00fcbersicht  Instanzvariablen     Variablenname  Beschreibung      Funktion  f  zu optimierendes Funktionsobjekt    point b  bester Simplexpunkt    point g  mittlerer Simplexpunkt    point w  schlechtester Simplexpunkt    double eps  Epsilon (Kovergenzkriterium)    double alpha_  Reflexionsfaktor    double gamma_  Expansionsfaktor    double beta_  Kontraktionsfaktor    double delta_  Komprimierungsfaktor    bool done  Zustandsvariable    size_t iter_c  Iterationsz\u00e4hler     Methoden     Methode  Beschreibung      - point  min(point , point )  returniert den kleineren (per Funktionswert) der beiden Punkte    - point  min(point , point , point )  returniert den kleinsten (per Funktionswert) der drei Punkte    - void sort_points_by_fvalue()  sortiert die drei Werte B, G, W sodass  f(B)  = f(G)  = f(W)    - void do_step()  f\u00fchrt einen Optimierungsschritt aus    + double alpha()  returniert Reflexionsfaktor    + double gamma()  returniert Expansionsfaktor    + double beta()  returniert Kontraktionsfaktor    + double delta()  returniert Komprimierungsfaktor    + void set_alpha(double)  setzt Reflexionsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + void set_gamma(double)  setzt Expansionsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + void set_beta(double)  setzt Kontraktionsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + void set_delta(double)  setzt Komprimierungsfaktor wenn m\u00f6glich, wirft sonst  invalid_value    + point best_point()  returniert besten Simplexpunkt    + std::tuple point, point, point  current_simplex()  returniert Tupel aller drei Simplexpunkte    + bool done()  returniert Zustandsvariable    + size_t iteration_count()  returniert den Wert des Iterationenz\u00e4hlers    + void step()  f\u00fchrt Optimierungsschritt aus, sortiert Punkte und setzt ggf. Zustandsvariable    + optimize()  f\u00fchrt die Optimierung die komplette Optimierung durch     Algorithmus selbst  Die Implementierung umfasst eine Optimiererklasse  nelder_mead_optimizer , der bei\nder Instanziierung diverse Parameter \u00fcbergeben werden m\u00fcssen:   Eine von der Klasse  Funktion  abgeleitete Funktionsrepr\u00e4sentation, die die\n  Methode  value(double, double)  bzw.  operator()(double, double)  implementiert\n  haben muss  3 Startpunkte  p1 ,  p2 ,  p3  der Form (x, y), die den Startsimplex konstruieren  Ein Double-Wert  eps , der den zu verwendenden Epsilon-Wert angibt [optional,\n  defaultm\u00e4\u00dfig .00001]  Ein Double-Wert f\u00fcr den Reflexionsfaktor  alpha  [optional, defaultm\u00e4\u00dfig 1]  Ein Double-Wert f\u00fcr den Expansionsfaktor  gamma  [optional, defaultm\u00e4\u00dfig 2]  Ein Double-Wert f\u00fcr den Kontraktionsfaktor  beta  [optional, defaultm\u00e4\u00dfig .5]  Ein Double-Wert f\u00fcr den Komprimierungsfaktor  delta  [optional, defaultm\u00e4\u00dfig .5]   Alle optionalen Werte k\u00f6nnen nachtr\u00e4glich mit dem entsprechenden Getter und\nSetter abgefragt und ge\u00e4ndert werden. Die Setter f\u00fcr die Verhaltensfaktoren alpha ,  beta ,  gamma  und  delta  pr\u00fcfen die Sinnhaftigkeit der \u00fcbergebenen\nWerte und werfen eine Exception des Typs  invalid_value  mit einer\nFehlermeldung sollten diese nicht stimmen.  Ein Minimalbeispiel zum Rauskopieren (unter src/nmo/simple.cpp zu finden):  #include  iostream \n#include  nelder_mead_optimizer.hpp \n\nint main() {\n    struct : Funktion {\n        double value(double x, double y) { return x*x + y*y; }\n    } fn;\n\n    nelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0000001);\n    nmo.optimize();\n    point min = nmo.best_point();\n\n    std::cout    The minimum is at     min.format()    !\\nNeeded  \n                nmo.iteration_count()     iterations.\\n ;  Vorhergehendes Beispiel instanziiert ein Optimiererobjekt  nmo , das die\nFunktion  fn  optimieren soll, mit den Startpunkten (-1, -5), (8, 8) und (3,\n-8). Das Epsilon f\u00fcr die Abbruchbedingung wurde als .0005 gew\u00e4hlt. Danach wird\ndie  optimize -Methode aufgerufen, die die Optimierung bis zum Erreichen des\nKonvergenzkriteriums durchf\u00fchrt. Anschlie\u00dfend kann der beste Punkt mittels get_best_point()  abgerufen werden. Die  point -Klasse liegt der\nImplementierung bei und umfasst die wichtigsten Vektor-Operationen sowie einen\nextrem coolen Initialisiererlisten-Konstruktor, der die kurze Anschreibweise im\nKonstruktoraufruf erm\u00f6glicht. Weiters wichtig sind die  format - und raw -Methoden, die den Inhalt des Punktes jeweils in einen String gie\u00dfen. format()  ist zur sch\u00f6nen Ausgabe gedacht und  raw()  als Zwischenmedium zur\nWeitergabe des Punktes an externe Programme (wie etwa gnuplot).  Um den Algorithmus m\u00f6glichst flexibel benutzen zu k\u00f6nnen, kann auch die Methode step  verwendet werden, um den Algorithmus schrittweise verfolgen zu k\u00f6nnen.\nAuskunft \u00fcber den Zustand gibt die  done  Methode. Folgendes Beispiel optimiert\neine Funktion wie das vorige, gibt bei jedem Schritt jedoch auch den\nderzeitigen Simplex aus.  nelder_mead_optimizer nmo(fn, {-1, -5}, {8, 8}, {3, -8}, .0005);\n\nwhile(!nmo.done()) {\n    std::cout    \\nIteration #    nmo.iteration_count()   '\\n';\n    auto points = nmo.current_simplex();\n\n    std::cout    B =     std::get 0 (points).format()   '\\n'\n                 G =     std::get 1 (points).format()   '\\n'\n                 W =     std::get 2 (points).format()   '\\n';\n\n    nmo.step();\n}  Testprogramm  Das Testprogramm ben\u00f6tigt POSIX-Pipes (i.e. ist nur auf Linux und ggf. auch OS\nX lauff\u00e4hig) und gnuplot zum darstellen des Optimierungsverlaufes. Folgende\nFunktionen sind vorimplementiert:   Himmelblau-Funktion (Befehl:  himmelblau )  Rosenbrocks Bananen-Funktion (Befehl:  banana )  Matyas-Funktion (Befehl:  matyas )  Dreih\u00f6cker-Kamelfunktion (Befehl:  camel )  Booth-Funktion (Befehl:  booth )  Beale-Funktion (Befehl:  beale )  Beispielfunktion 1,  3*x**2 + y**2 - 3*x*y - 3*x  (Befehl:  example1 )  Beispielfunktion 2,  y**4 + 2*x**2 - 3*x*y + 1  (Befehl:  example2 )  Beispielfunktion 3,  3*x**2 + y + y**2  (Befehl:  example3 )   Ein Aufruf sieht folgenderma\u00dfen aus:  ./nelder_mead [FUNKTIONSNAME] . Per\ndefault schl\u00e4ft das Programm zwischen Iterationsschritten, um das betrachten\nder Ausgabegraphen zu erm\u00f6glichen. Ist dies nicht genug, kann via ./nelder_mead [FUNKTIONSNAME] manual  erwirkt werden, dass auf eine beliebige\nUsereingabe gewartet wird.  Weiters ist eine kleine Informationsfunktion eingebaut. Mittels  ./nelder_mead\ninfo [FUNKTIONSNAME]  kann diese aufgerufen werden und liefert dann\nbeispielsweise solche Ausgaben:  $ ./nelder_mead info himmelblau\n\nH I M M E L B L A U  function\nThe Himmelblau function is commonly used for benchmarking optimization\nalgorithms. It is defined as\n                    2          2         2     2\n        f(x, y) = (x  + y - 11)  + (x + y  - 7)\n\nIts minima are at positions\n    f(3.2, 2.0) = 0.0\n    f(-2.805118, 3.131312) = 0.0\n    f(-3.779310, -3.283186) = 0.0\n    f(3.584428, -1.848126) = 0.0  Es werden zumindest die Funktionsdefinition sowie die Minima ausgegeben.  Werden dem Programm keine Argumente \u00fcbergeben, beschwert es sich\ndementsprechend und zeigt eine kleine Hilfe mit den unterst\u00fctzten\nFunktionalit\u00e4ten an. \u00dcbersch\u00fcssige Argumente werden ignoriert.  Links  Files auf GitHub (garantiert aktuell)  nelder_mead.zip",
            "title": "Implementation"
        },
        {
            "location": "/gradienten/",
            "text": "Die Idee und der Zweck des Gradientenverfahren\n\n\nGrunds\u00e4tzlich ist das Gradientenverfahren ein Optimierungsverfahren, welches das Minimum einer mehrdimensionalen Funktion errechnen. Der Gradient \n\u2207f(x,y)\n einer Funktion \nf(x)\n zeigt, aus sp\u00e4ter gezeigten Gr\u00fcnden, immer in die Richtung des steilsten Anstiegs, folglich zeigt \n-\u2207f(x,y)\n in die Richtung des st\u00e4rksten Abstiegs. Das Gradientenverfahren macht sich dies zunutze und man \"wandert\" eine gewisse Dauer in diese Richtung, wie \"lange\" man in die errechnete Richtung \"wandert\" h\u00e4ngt unter anderem auch von der gew\u00e4hlten Methode ab.\n\n\nDer Ablauf des Gradientenverfahrens\n\n\n\n\nEs wird ein beliebiger Startpunkt \nP=(x,y)\n ausgew\u00e4hlt.\n\n\nEs wird die Ableitung der Funktion \nf(x,y)\n, also \n\u2207f(x)\n gebildet. Sollte dieser Gradient bereits den Wert null haben sind wir bereits fertig und haben ein lokales Minimum.\n\n\nDer Punkt \nP\n wird in den Gradienten eingesetzt und der negative Wert berechnet, also \n-\u2207f(x_{P},y_{P})\n.\n\n\nUm eine neuen Punkt \nP^([n+1])\n zu finden stellen wir nun folgende Gleichung auf: \nP^([n+1]) = P^([n]) + \u03b1[n] * s^([n])\n. Nun haben wir die Richtung in die optimiert werden muss gefunden (\ns^([n])\n (\n=-\u2207f(x_{P},y_{P})\n)), jetzt muss noch entschieden werden wie weit wir in diese Richtung \"wandern\" (\n\u03b1[n]\n, liegt zwischen \n0\n und \n1\n) (Hinweis: \nn\n ist die aktuelle Iteration).\n\n\n\n\nDas kann man einerseits mit Hilfe eines fixen Werts machen, andererseits auch mit einer Folge (wie z.B \n1 / sqrt(n)\n)\noder einer jedes mal neu errechneten Schrittweite. Zu beachten ist, dass die ausgew\u00e4hlte Folge auf jeden Fall divergent sein muss, da man sonst bis zu einer maximalen Entfernung \"wandern\"\nkann und die Wahrscheinlichkeit gro\u00df ist das Optimum nie zu erreichen. Sollte man jedes mal einen fixen Wert verliert man zwar den Aufwand f\u00fcr die Berechnung der Schrittweite, jedoch ist die Wahrscheinlichkeit hoch, dass man viele Iterationen ben\u00f6tigt oder in einer endlosen Schleife festh\u00e4ngt.\n\n\nEs gibt verschieden Arten wie man die Schrittweite berechnen kann, im Folgenden werde ich die Schrittweitenbestimmung nach Armijo erkl\u00e4ren. Dieses Verfahren ist eines der sogenannten \"line-search\" Verfahren, das von mir gezeigte ist jedoch kein exaktes line-search Verfahren sondern lediglich eine einfache Heuristik.\n\n\nDie Armijo-Bedingung\n\n\n\u03c6(\u03b1) \u2264 \u03c6(0) + c * \u03b1^{[n]} * \u03c6(0)'.\n\n\n\nWobei \nc\n eine Konstante zwischen null und eins ist und dazu dient das die Bedingung nicht zu restriktiv ist, \n\u03c6(\u03b1) = f(P^([n]) + \u03b1^([n]) * s^([n]))\n und \n\u03c6(0)' = \u2207f(P^{n}) * s^{[n]}\n\n\n\n\nF\u00fcr den Anfang wird \n\u03b1=1\n gew\u00e4hlt und errechnet ob die Armijo-Bedingung erf\u00fcllt ist - sollte sie erf\u00fcllt sein haben wir ein passende \n\u03b1\n gefunden, wenn nicht wird \n\u03b1\n mit einem \n\u03b2\n, welches ebenfalls zwischen null und eins liegt, multipliziert und wieder gepr\u00fcft ob die Ungleichung erf\u00fcllt ist. (Hinweis: In der Praxis liefern die Werte \nc = 0.01\n und \n\u03b2 = 0.9\n h\u00e4ufig gute Ergebnisse. \n1\n \n2\n\n\nWenn man einen neuen Punkt gefunden hat wird bei Punkt 3 fortgesetzt. Da es oft einen gro\u00dfen Rechenaufwand erfordert das genaue Minimum zu finden wird das Verfahren meist beendet wenn der Gradient einen akzeptablen Wert erreicht hat (So kann man als Abbruchbedingung z.B. die st\u00e4rke des Anstiegs in einem Punkt (also den Betrag des Gradienten) nehmen).",
            "title": "Gradientenverfahren"
        },
        {
            "location": "/gradienten/#die-idee-und-der-zweck-des-gradientenverfahren",
            "text": "Grunds\u00e4tzlich ist das Gradientenverfahren ein Optimierungsverfahren, welches das Minimum einer mehrdimensionalen Funktion errechnen. Der Gradient  \u2207f(x,y)  einer Funktion  f(x)  zeigt, aus sp\u00e4ter gezeigten Gr\u00fcnden, immer in die Richtung des steilsten Anstiegs, folglich zeigt  -\u2207f(x,y)  in die Richtung des st\u00e4rksten Abstiegs. Das Gradientenverfahren macht sich dies zunutze und man \"wandert\" eine gewisse Dauer in diese Richtung, wie \"lange\" man in die errechnete Richtung \"wandert\" h\u00e4ngt unter anderem auch von der gew\u00e4hlten Methode ab.",
            "title": "Die Idee und der Zweck des Gradientenverfahren"
        },
        {
            "location": "/gradienten/#der-ablauf-des-gradientenverfahrens",
            "text": "Es wird ein beliebiger Startpunkt  P=(x,y)  ausgew\u00e4hlt.  Es wird die Ableitung der Funktion  f(x,y) , also  \u2207f(x)  gebildet. Sollte dieser Gradient bereits den Wert null haben sind wir bereits fertig und haben ein lokales Minimum.  Der Punkt  P  wird in den Gradienten eingesetzt und der negative Wert berechnet, also  -\u2207f(x_{P},y_{P}) .  Um eine neuen Punkt  P^([n+1])  zu finden stellen wir nun folgende Gleichung auf:  P^([n+1]) = P^([n]) + \u03b1[n] * s^([n]) . Nun haben wir die Richtung in die optimiert werden muss gefunden ( s^([n])  ( =-\u2207f(x_{P},y_{P}) )), jetzt muss noch entschieden werden wie weit wir in diese Richtung \"wandern\" ( \u03b1[n] , liegt zwischen  0  und  1 ) (Hinweis:  n  ist die aktuelle Iteration).   Das kann man einerseits mit Hilfe eines fixen Werts machen, andererseits auch mit einer Folge (wie z.B  1 / sqrt(n) )\noder einer jedes mal neu errechneten Schrittweite. Zu beachten ist, dass die ausgew\u00e4hlte Folge auf jeden Fall divergent sein muss, da man sonst bis zu einer maximalen Entfernung \"wandern\"\nkann und die Wahrscheinlichkeit gro\u00df ist das Optimum nie zu erreichen. Sollte man jedes mal einen fixen Wert verliert man zwar den Aufwand f\u00fcr die Berechnung der Schrittweite, jedoch ist die Wahrscheinlichkeit hoch, dass man viele Iterationen ben\u00f6tigt oder in einer endlosen Schleife festh\u00e4ngt.  Es gibt verschieden Arten wie man die Schrittweite berechnen kann, im Folgenden werde ich die Schrittweitenbestimmung nach Armijo erkl\u00e4ren. Dieses Verfahren ist eines der sogenannten \"line-search\" Verfahren, das von mir gezeigte ist jedoch kein exaktes line-search Verfahren sondern lediglich eine einfache Heuristik.",
            "title": "Der Ablauf des Gradientenverfahrens"
        },
        {
            "location": "/gradienten/#die-armijo-bedingung",
            "text": "\u03c6(\u03b1) \u2264 \u03c6(0) + c * \u03b1^{[n]} * \u03c6(0)'.  Wobei  c  eine Konstante zwischen null und eins ist und dazu dient das die Bedingung nicht zu restriktiv ist,  \u03c6(\u03b1) = f(P^([n]) + \u03b1^([n]) * s^([n]))  und  \u03c6(0)' = \u2207f(P^{n}) * s^{[n]}   F\u00fcr den Anfang wird  \u03b1=1  gew\u00e4hlt und errechnet ob die Armijo-Bedingung erf\u00fcllt ist - sollte sie erf\u00fcllt sein haben wir ein passende  \u03b1  gefunden, wenn nicht wird  \u03b1  mit einem  \u03b2 , welches ebenfalls zwischen null und eins liegt, multipliziert und wieder gepr\u00fcft ob die Ungleichung erf\u00fcllt ist. (Hinweis: In der Praxis liefern die Werte  c = 0.01  und  \u03b2 = 0.9  h\u00e4ufig gute Ergebnisse.  1   2  Wenn man einen neuen Punkt gefunden hat wird bei Punkt 3 fortgesetzt. Da es oft einen gro\u00dfen Rechenaufwand erfordert das genaue Minimum zu finden wird das Verfahren meist beendet wenn der Gradient einen akzeptablen Wert erreicht hat (So kann man als Abbruchbedingung z.B. die st\u00e4rke des Anstiegs in einem Punkt (also den Betrag des Gradienten) nehmen).",
            "title": "Die Armijo-Bedingung"
        },
        {
            "location": "/koordinatenabstieg/",
            "text": "Einf\u00fchrung\n\n\nBei der Koordinatenabstiegsmethode wird bei jedem Schritt eine Koordinate \ni\n gew\u00e4hlt, nach der man optimiert. Es wird bei einem beliebigen Startpunkt begonnen und in jedem Iterationsschritt setzt man alle Koordinaten des aktuellen Punktes in die Funktion ein, nur die Koordinate, nach der man minimieren will, beh\u00e4lt man als Variable bei.\n\n\nEs wird immer in Richtung einer Achse minimiert und die Stelle, an der das Minimum ist, als neue Koordinate beibehalten und so gelangt man mit einer Anzahl an Iterationen zum Minimum der Funktion.\n\n\nWenn zum Beispiel die Funktion \nf(x,y)=2x^{2}+2xy+1.5y^{2}\n und der Startpunkt \nP=(1,\\,1)\n gegeben ist, so muss man, wenn entlang der \nx\n-Achse minimiert werden soll folgendes eingesetzt werden:\n\n\nx = 1+1d\ny = 1+0d\n\n\n\nSoll entlang der $y$-Achse optimiert werden, so muss folgendes eingesetzt werden:\n\n\nx = 1+0d\ny = 1+1d\n\n\n\nBeispiel\n\n\nWir m\u00f6chten die Funktion \nf(x,y)=2x^{2}+2xy+1.5y^{2}\n optimieren und w\u00e4hlen den Startpunkt \nP_{0}=(1,\\,1)\n. Wir minimieren zuerst entlang der \nx\n-Achse und setzen ein\n\n\nf(d) = 2(1+d)^{2}+2(1+d)+1.5\n     = 2d^{2}+6d+5.5\n\n\n\nDiese soeben erhaltene Funktion m\u00fcssen wir nun noch minimieren.\n\n\nf'(d) = 4d+6\n4d+6 = 0\nd = -3/2\n\n\n\nSetzen wir dies in die Gleichung f\u00fcr die \nx\n-Koordinate ein und verwenden die alte \ny\n-Koordinate erhalten wir den neuen Punkt \nP_{1}=(-1/2 , 1)\n. Nun minimieren wir nach \ny\n, wir setzen also ein:\n\n\nx = -1/2 + 0d\ny = 1+1d\n\n\n\nund erhalten\n\n\nf(d)=1.5d^{2}-d+6\n\n\n\nDies minimieren wir wiederum und erhalten die neue \ny\n-Koordinate \n1/3\n. Damit haben wir den neuen Punkt \n(-1/2 , 1/3)\n.\nDieser Vorgang wird wiederholt, bis sich die errechneten Werte nurnoch marginal unterscheiden. Danach wird abgebrochen.\n\n\nImplementation\n\n\nKlassen\u00fcbersicht\n\n\nInstanzvariablen\n\n\n\n\n\n\n\n\nVariablenname\n\n\nBeschreibung\n\n\n\n\n\n\n\n\n\n\nFunktion\n f\n\n\nzu optimierendes Funktionsobjekt\n\n\n\n\n\n\npoint p\n\n\nderzeitiger Punkt\n\n\n\n\n\n\npoint q\n\n\nletzter Punkt\n\n\n\n\n\n\ndouble eps\n\n\nEpsilon (Kovergenzkriterium)\n\n\n\n\n\n\ndouble golden_ratio\n\n\nGoldener Schnitt (Minimierungsalgorithmus)\n\n\n\n\n\n\nbool is_done\n\n\nZustandsvariable\n\n\n\n\n\n\nbool x_last\n\n\nZustandvariable: wurde x als letztes optimiert?\n\n\n\n\n\n\nsize_t iter_c\n\n\nIterationsz\u00e4hler\n\n\n\n\n\n\ndouble lo_x\n\n\nUntergrenze eindimensionale Optimierung (x)\n\n\n\n\n\n\ndouble hi_x\n\n\nObergrenze eindimensionale Optimierung (x)\n\n\n\n\n\n\ndouble lo_y\n\n\nUntergrenze eindimensionale Optimierung (y)\n\n\n\n\n\n\ndouble hi_y\n\n\nObergrenze eindimensionale Optimierung (y)\n\n\n\n\n\n\n\n\nMethoden\n\n\n\n\n\n\n\n\nMethode\n\n\nBeschreibung\n\n\n\n\n\n\n\n\n\n\n- double minimize_with_x_constant(double) const\n\n\nMinimiert die Funktion mit einem konstanten Wert f\u00fcr x\n\n\n\n\n\n\n- double minimize_with_x_constant(double) const\n\n\nMinimiert die Funktion mit einem konstanten Wert f\u00fcr y\n\n\n\n\n\n\n- void do_halfstep()\n\n\nF\u00fchrt einen Optimierungsschritt durch (optimiert eine Variable)\n\n\n\n\n\n\n+ point current_point() const\n\n\nreturniert p\n\n\n\n\n\n\n+ point last_point() const\n\n\nreturniert q\n\n\n\n\n\n\n+ void step()\n\n\nf\u00fchrt einen Optimierungsschritt durch\n\n\n\n\n\n\n+ bool done()\n\n\nreturniert Zustandsvariable\n\n\n\n\n\n\n+ size_t iteration_count()\n\n\nreturniert den Wert des Iterationenz\u00e4hlers\n\n\n\n\n\n\n+ void step()\n\n\nf\u00fchrt Optimierungsschritt aus, sortiert Punkte und setzt ggf. Zustandsvariable\n\n\n\n\n\n\n+ optimize()\n\n\nf\u00fchrt die komplette Optimierung durch\n\n\n\n\n\n\n+ lower_bound_x()\n\n\nReturniert die Untergrenze f\u00fcr x\n\n\n\n\n\n\n+ upper_bound_x()\n\n\nReturniert die Obergrenze f\u00fcr x\n\n\n\n\n\n\n+ lower_bound_y()\n\n\nReturniert die Untergrenze f\u00fcr y\n\n\n\n\n\n\n+ upper_bound_y()\n\n\nReturniert die Obergrenze f\u00fcr y\n\n\n\n\n\n\n+ set_lower_bound_x(double)\n\n\nSetzt die neue Untergrenze f\u00fcr x. Invariante: lo_x \n hi_x\n\n\n\n\n\n\n+ set_upper_bound_x(double)\n\n\nSetzt die neue Obergrenze f\u00fcr x. Invariante: hi_x \n lo_x\n\n\n\n\n\n\n+ set_lower_bound_y(double)\n\n\nSetzt die neue Untergrenze f\u00fcr y. Invariante: lo_y \n hi_y\n\n\n\n\n\n\n+ set_upper_bound_y(double)\n\n\nSetzt die neue Obergrenze f\u00fcr y. Invariante: hi_y \n lo_y\n\n\n\n\n\n\n\n\nAlgorithmus selbst\n\n\nDie Implementierung umfasst eine Optimiererklasse \ncoordesc_optimizer\n, der bei\nder Instanziierung diverse Parameter \u00fcbergeben werden m\u00fcssen:\n\n\n\n\nEine von der Klasse \nFunktion\n abgeleitete Funktionsrepr\u00e4sentation, die die\n  Methode \nvalue(double, double)\n bzw. \noperator()(double, double)\n implementiert\n  haben muss\n\n\n1 Startpunkt \np1\n, der ruhig zuf\u00e4llig gew\u00e4hlt werden kann\n\n\nEin Double-Wert \neps\n, der den zu verwendenden Epsilon-Wert angibt [optional,\n  defaultm\u00e4\u00dfig .00001]\n\n\n\n\nAlle optionalen Werte k\u00f6nnen nachtr\u00e4glich mit dem entsprechenden Getter und\nSetter abgefragt und ge\u00e4ndert werden. Die Setter f\u00fcr die Verhaltensfaktoren\n\nalpha\n, \nbeta\n, \ngamma\n und \ndelta\n pr\u00fcfen die Sinnhaftigkeit der \u00fcbergebenen\nWerte und werfen eine Exception des Typs \ninvalid_value\n mit einer\nFehlermeldung sollten diese nicht stimmen.\n\n\nEin Minimalbeispiel zum Rauskopieren:\n\n\ncoordesc_optimizer cdo(fn, {-1, -5}, .0000001);\ncdo.optimize();\npoint min = cdo.current_point();\n\nstd::cout \n \nThe minimum is at \n \n min.format() \n \n!\\nNeeded \n\n          \n cdo.iteration_count() \n \n iterations.\\n\n;\n\n\n\n\nVorhergehendes Beispiel instanziiert ein Optimiererobjekt \ncdo\n, das die\nFunktion \nfn\n optimieren soll, mit dem Startpunkt (-1, -5)\n. Das Epsilon f\u00fcr die Abbruchbedingung wurde als .0005 gew\u00e4hlt. Danach wird\ndie \noptimize\n-Methode aufgerufen, die die Optimierung bis zum Erreichen des\nKonvergenzkriteriums durchf\u00fchrt. Anschlie\u00dfend kann der gefundene Punkt mittels\n\ncurrent_point()\n abgerufen werden. Die \npoint\n-Klasse liegt der\nImplementierung bei und umfasst die wichtigsten Vektor-Operationen sowie einen\nextrem coolen Initialisiererlisten-Konstruktor, der die kurze Anschreibweise im\nKonstruktoraufruf erm\u00f6glicht. Weiters wichtig sind die \nformat\n- und\n\nraw\n-Methoden, die den Inhalt des Punktes jeweils in einen String gie\u00dfen.\n\nformat()\n ist zur sch\u00f6nen Ausgabe gedacht und \nraw()\n als Zwischenmedium zur\nWeitergabe des Punktes an externe Programme (wie etwa gnuplot).\n\n\nUm den Algorithmus m\u00f6glichst flexibel benutzen zu k\u00f6nnen, kann auch die Methode\n\nstep\n verwendet werden, um den Algorithmus schrittweise verfolgen zu k\u00f6nnen.\nAuskunft \u00fcber den Zustand gibt die \ndone\n Methode. Folgendes Beispiel optimiert\neine Funktion wie das vorige, gibt bei jedem Schritt jedoch auch den\nderzeitigen Punkt aus.\n\n\ncoordesc_optimizer cdo(fn, {-1, -5}, .0005);\n\nwhile(!nmo.done()) {\n    std::cout \n \n\\nIteration #\n \n cdo.iteration_count() \n '\\n';\n    point p = cdo.current_point();\n    std::cout \n \nP = \n \n p.format() \n '\\n';\n    cdo.step();\n}\n\n\n\n\nTestprogramm\n\n\nDas Testprogramm ben\u00f6tigt POSIX-Pipes (i.e. ist nur auf Linux und ggf. auch OS\nX lauff\u00e4hig) und gnuplot zum darstellen des Optimierungsverlaufes. Folgende\nFunktionen sind vorimplementiert:\n\n\n\n\nHimmelblau-Funktion (Befehl: \nhimmelblau\n)\n\n\nRosenbrocks Bananen-Funktion (Befehl: \nbanana\n)\n\n\nMatyas-Funktion (Befehl: \nmatyas\n)\n\n\nDreih\u00f6cker-Kamelfunktion (Befehl: \ncamel\n)\n\n\nBooth-Funktion (Befehl: \nbooth\n)\n\n\nBeale-Funktion (Befehl: \nbeale\n)\n\n\nBeispielfunktion 1, \n3*x**2 + y**2 - 3*x*y - 3*x\n (Befehl: \nexample1\n)\n\n\nBeispielfunktion 2, \ny**4 + 2*x**2 - 3*x*y + 1\n (Befehl: \nexample2\n)\n\n\nBeispielfunktion 3, \n3*x**2 + y + y**2\n (Befehl: \nexample3\n)\n\n\nBeispielfunktion 4, \n5*x**2 - 6*x*y + 5*y**2 - 0.0259\n (Befehl: \nexample4\n)\n\n\n\n\nEin Aufruf sieht folgenderma\u00dfen aus: \n./coordesc [FUNKTIONSNAME]\n. Per\ndefault schl\u00e4ft das Programm zwischen Iterationsschritten, um das betrachten\nder Ausgabegraphen zu erm\u00f6glichen. Ist dies nicht genug, kann via\n\n./coordesc [FUNKTIONSNAME] manual\n erwirkt werden, dass auf eine beliebige\nUsereingabe gewartet wird.\n\n\nWeiters ist eine kleine Informationsfunktion eingebaut. Mittels \n./coordesc\ninfo [FUNKTIONSNAME]\n kann diese aufgerufen werden und liefert dann\nbeispielsweise solche Ausgaben:\n\n\n$ ./nelder_mead info himmelblau\n\nH I M M E L B L A U  function\nThe Himmelblau function is commonly used for benchmarking optimization\nalgorithms. It is defined as\n                    2          2         2     2\n        f(x, y) = (x  + y - 11)  + (x + y  - 7)\n\nIts minima are at positions\n    f(3.2, 2.0) = 0.0\n    f(-2.805118, 3.131312) = 0.0\n    f(-3.779310, -3.283186) = 0.0\n    f(3.584428, -1.848126) = 0.0\n\n\n\n\nEs werden zumindest die Funktionsdefinition sowie die Minima ausgegeben.\n\n\nWerden dem Programm keine Argumente \u00fcbergeben, beschwert es sich\ndementsprechend und zeigt eine kleine Hilfe mit den unterst\u00fctzten\nFunktionalit\u00e4ten an. \u00dcbersch\u00fcssige Argumente werden ignoriert.\n\n\nLinks\n\n\nFiles auf GitHub (garantiert aktuell)\n\n\nnelder_mead.zip",
            "title": "Koordinatenabstiegsmethode"
        },
        {
            "location": "/koordinatenabstieg/#einfuhrung",
            "text": "Bei der Koordinatenabstiegsmethode wird bei jedem Schritt eine Koordinate  i  gew\u00e4hlt, nach der man optimiert. Es wird bei einem beliebigen Startpunkt begonnen und in jedem Iterationsschritt setzt man alle Koordinaten des aktuellen Punktes in die Funktion ein, nur die Koordinate, nach der man minimieren will, beh\u00e4lt man als Variable bei.  Es wird immer in Richtung einer Achse minimiert und die Stelle, an der das Minimum ist, als neue Koordinate beibehalten und so gelangt man mit einer Anzahl an Iterationen zum Minimum der Funktion.  Wenn zum Beispiel die Funktion  f(x,y)=2x^{2}+2xy+1.5y^{2}  und der Startpunkt  P=(1,\\,1)  gegeben ist, so muss man, wenn entlang der  x -Achse minimiert werden soll folgendes eingesetzt werden:  x = 1+1d\ny = 1+0d  Soll entlang der $y$-Achse optimiert werden, so muss folgendes eingesetzt werden:  x = 1+0d\ny = 1+1d",
            "title": "Einf\u00fchrung"
        },
        {
            "location": "/koordinatenabstieg/#beispiel",
            "text": "Wir m\u00f6chten die Funktion  f(x,y)=2x^{2}+2xy+1.5y^{2}  optimieren und w\u00e4hlen den Startpunkt  P_{0}=(1,\\,1) . Wir minimieren zuerst entlang der  x -Achse und setzen ein  f(d) = 2(1+d)^{2}+2(1+d)+1.5\n     = 2d^{2}+6d+5.5  Diese soeben erhaltene Funktion m\u00fcssen wir nun noch minimieren.  f'(d) = 4d+6\n4d+6 = 0\nd = -3/2  Setzen wir dies in die Gleichung f\u00fcr die  x -Koordinate ein und verwenden die alte  y -Koordinate erhalten wir den neuen Punkt  P_{1}=(-1/2 , 1) . Nun minimieren wir nach  y , wir setzen also ein:  x = -1/2 + 0d\ny = 1+1d  und erhalten  f(d)=1.5d^{2}-d+6  Dies minimieren wir wiederum und erhalten die neue  y -Koordinate  1/3 . Damit haben wir den neuen Punkt  (-1/2 , 1/3) .\nDieser Vorgang wird wiederholt, bis sich die errechneten Werte nurnoch marginal unterscheiden. Danach wird abgebrochen.",
            "title": "Beispiel"
        },
        {
            "location": "/koordinatenabstieg/#implementation",
            "text": "Klassen\u00fcbersicht  Instanzvariablen     Variablenname  Beschreibung      Funktion  f  zu optimierendes Funktionsobjekt    point p  derzeitiger Punkt    point q  letzter Punkt    double eps  Epsilon (Kovergenzkriterium)    double golden_ratio  Goldener Schnitt (Minimierungsalgorithmus)    bool is_done  Zustandsvariable    bool x_last  Zustandvariable: wurde x als letztes optimiert?    size_t iter_c  Iterationsz\u00e4hler    double lo_x  Untergrenze eindimensionale Optimierung (x)    double hi_x  Obergrenze eindimensionale Optimierung (x)    double lo_y  Untergrenze eindimensionale Optimierung (y)    double hi_y  Obergrenze eindimensionale Optimierung (y)     Methoden     Methode  Beschreibung      - double minimize_with_x_constant(double) const  Minimiert die Funktion mit einem konstanten Wert f\u00fcr x    - double minimize_with_x_constant(double) const  Minimiert die Funktion mit einem konstanten Wert f\u00fcr y    - void do_halfstep()  F\u00fchrt einen Optimierungsschritt durch (optimiert eine Variable)    + point current_point() const  returniert p    + point last_point() const  returniert q    + void step()  f\u00fchrt einen Optimierungsschritt durch    + bool done()  returniert Zustandsvariable    + size_t iteration_count()  returniert den Wert des Iterationenz\u00e4hlers    + void step()  f\u00fchrt Optimierungsschritt aus, sortiert Punkte und setzt ggf. Zustandsvariable    + optimize()  f\u00fchrt die komplette Optimierung durch    + lower_bound_x()  Returniert die Untergrenze f\u00fcr x    + upper_bound_x()  Returniert die Obergrenze f\u00fcr x    + lower_bound_y()  Returniert die Untergrenze f\u00fcr y    + upper_bound_y()  Returniert die Obergrenze f\u00fcr y    + set_lower_bound_x(double)  Setzt die neue Untergrenze f\u00fcr x. Invariante: lo_x   hi_x    + set_upper_bound_x(double)  Setzt die neue Obergrenze f\u00fcr x. Invariante: hi_x   lo_x    + set_lower_bound_y(double)  Setzt die neue Untergrenze f\u00fcr y. Invariante: lo_y   hi_y    + set_upper_bound_y(double)  Setzt die neue Obergrenze f\u00fcr y. Invariante: hi_y   lo_y     Algorithmus selbst  Die Implementierung umfasst eine Optimiererklasse  coordesc_optimizer , der bei\nder Instanziierung diverse Parameter \u00fcbergeben werden m\u00fcssen:   Eine von der Klasse  Funktion  abgeleitete Funktionsrepr\u00e4sentation, die die\n  Methode  value(double, double)  bzw.  operator()(double, double)  implementiert\n  haben muss  1 Startpunkt  p1 , der ruhig zuf\u00e4llig gew\u00e4hlt werden kann  Ein Double-Wert  eps , der den zu verwendenden Epsilon-Wert angibt [optional,\n  defaultm\u00e4\u00dfig .00001]   Alle optionalen Werte k\u00f6nnen nachtr\u00e4glich mit dem entsprechenden Getter und\nSetter abgefragt und ge\u00e4ndert werden. Die Setter f\u00fcr die Verhaltensfaktoren alpha ,  beta ,  gamma  und  delta  pr\u00fcfen die Sinnhaftigkeit der \u00fcbergebenen\nWerte und werfen eine Exception des Typs  invalid_value  mit einer\nFehlermeldung sollten diese nicht stimmen.  Ein Minimalbeispiel zum Rauskopieren:  coordesc_optimizer cdo(fn, {-1, -5}, .0000001);\ncdo.optimize();\npoint min = cdo.current_point();\n\nstd::cout    The minimum is at     min.format()    !\\nNeeded  \n            cdo.iteration_count()     iterations.\\n ;  Vorhergehendes Beispiel instanziiert ein Optimiererobjekt  cdo , das die\nFunktion  fn  optimieren soll, mit dem Startpunkt (-1, -5)\n. Das Epsilon f\u00fcr die Abbruchbedingung wurde als .0005 gew\u00e4hlt. Danach wird\ndie  optimize -Methode aufgerufen, die die Optimierung bis zum Erreichen des\nKonvergenzkriteriums durchf\u00fchrt. Anschlie\u00dfend kann der gefundene Punkt mittels current_point()  abgerufen werden. Die  point -Klasse liegt der\nImplementierung bei und umfasst die wichtigsten Vektor-Operationen sowie einen\nextrem coolen Initialisiererlisten-Konstruktor, der die kurze Anschreibweise im\nKonstruktoraufruf erm\u00f6glicht. Weiters wichtig sind die  format - und raw -Methoden, die den Inhalt des Punktes jeweils in einen String gie\u00dfen. format()  ist zur sch\u00f6nen Ausgabe gedacht und  raw()  als Zwischenmedium zur\nWeitergabe des Punktes an externe Programme (wie etwa gnuplot).  Um den Algorithmus m\u00f6glichst flexibel benutzen zu k\u00f6nnen, kann auch die Methode step  verwendet werden, um den Algorithmus schrittweise verfolgen zu k\u00f6nnen.\nAuskunft \u00fcber den Zustand gibt die  done  Methode. Folgendes Beispiel optimiert\neine Funktion wie das vorige, gibt bei jedem Schritt jedoch auch den\nderzeitigen Punkt aus.  coordesc_optimizer cdo(fn, {-1, -5}, .0005);\n\nwhile(!nmo.done()) {\n    std::cout    \\nIteration #    cdo.iteration_count()   '\\n';\n    point p = cdo.current_point();\n    std::cout    P =     p.format()   '\\n';\n    cdo.step();\n}  Testprogramm  Das Testprogramm ben\u00f6tigt POSIX-Pipes (i.e. ist nur auf Linux und ggf. auch OS\nX lauff\u00e4hig) und gnuplot zum darstellen des Optimierungsverlaufes. Folgende\nFunktionen sind vorimplementiert:   Himmelblau-Funktion (Befehl:  himmelblau )  Rosenbrocks Bananen-Funktion (Befehl:  banana )  Matyas-Funktion (Befehl:  matyas )  Dreih\u00f6cker-Kamelfunktion (Befehl:  camel )  Booth-Funktion (Befehl:  booth )  Beale-Funktion (Befehl:  beale )  Beispielfunktion 1,  3*x**2 + y**2 - 3*x*y - 3*x  (Befehl:  example1 )  Beispielfunktion 2,  y**4 + 2*x**2 - 3*x*y + 1  (Befehl:  example2 )  Beispielfunktion 3,  3*x**2 + y + y**2  (Befehl:  example3 )  Beispielfunktion 4,  5*x**2 - 6*x*y + 5*y**2 - 0.0259  (Befehl:  example4 )   Ein Aufruf sieht folgenderma\u00dfen aus:  ./coordesc [FUNKTIONSNAME] . Per\ndefault schl\u00e4ft das Programm zwischen Iterationsschritten, um das betrachten\nder Ausgabegraphen zu erm\u00f6glichen. Ist dies nicht genug, kann via ./coordesc [FUNKTIONSNAME] manual  erwirkt werden, dass auf eine beliebige\nUsereingabe gewartet wird.  Weiters ist eine kleine Informationsfunktion eingebaut. Mittels  ./coordesc\ninfo [FUNKTIONSNAME]  kann diese aufgerufen werden und liefert dann\nbeispielsweise solche Ausgaben:  $ ./nelder_mead info himmelblau\n\nH I M M E L B L A U  function\nThe Himmelblau function is commonly used for benchmarking optimization\nalgorithms. It is defined as\n                    2          2         2     2\n        f(x, y) = (x  + y - 11)  + (x + y  - 7)\n\nIts minima are at positions\n    f(3.2, 2.0) = 0.0\n    f(-2.805118, 3.131312) = 0.0\n    f(-3.779310, -3.283186) = 0.0\n    f(3.584428, -1.848126) = 0.0  Es werden zumindest die Funktionsdefinition sowie die Minima ausgegeben.  Werden dem Programm keine Argumente \u00fcbergeben, beschwert es sich\ndementsprechend und zeigt eine kleine Hilfe mit den unterst\u00fctzten\nFunktionalit\u00e4ten an. \u00dcbersch\u00fcssige Argumente werden ignoriert.  Links  Files auf GitHub (garantiert aktuell)  nelder_mead.zip",
            "title": "Implementation"
        }
    ]
}