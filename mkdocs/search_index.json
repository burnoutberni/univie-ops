{
    "docs": [
        {
            "location": "/",
            "text": "Nelder-Mead-Verfahren\n\n\nDas Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabh\u00e4ngige Punkte gew\u00e4hlt werden (also ein Simplex gebildet wird) aus denen der \u201eschlechteste\u201c Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch n\u00e4hert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen F\u00e4llen auf lokale Nebenoptima konvergieren kann. Hierf\u00fcr gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu l\u00f6sen.\n\n\nAbstiegsverfahren\n\n\nDas Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d hei\u00dft Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt: \nf (x + td) < f (x)\n f\u00fcr jedes \n0 < t < T\n. Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir k\u00f6nnen auch sagen, dass wenn \n\u2207f (x)T d < 0\n gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.\n\n\nGradientenverfahren\n\n\nGrunds\u00e4tzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des st\u00e4rksten Anstiegs zeigt. Dementsprechend zeigt nat\u00fcrlich der negative Gradient in die Richtung des st\u00e4rksten Abstiegs. Nun \u201egeht\u201c man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl st\u00e4rker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.\n\n\nKoordinatenabstiegsmethode\n\n\nBei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gew\u00e4hlt, nach der optimiert wird. Der Startpunkt ist beliebig w\u00e4hlbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gew\u00e4hlte Koordinate i beh\u00e4lt man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum ver\u00e4ndert; danach wird abgebrochen.",
            "title": "Home"
        },
        {
            "location": "/#nelder-mead-verfahren",
            "text": "Das Nelder-Mead-Verfahren wird zur Optimierung nichtlinearer Funktionen eingesetzt und ist in der Praxis weit verbreitet. Die Grundidee besteht darin, dass n+1 unabh\u00e4ngige Punkte gew\u00e4hlt werden (also ein Simplex gebildet wird) aus denen der \u201eschlechteste\u201c Punkt ermittelt wird und dann durch einen anderen ersetzt wird. Dadurch n\u00e4hert sich der Algorithmus schrittweise dem Optimum an, wobei er in manchen F\u00e4llen auf lokale Nebenoptima konvergieren kann. Hierf\u00fcr gibt es Anpassungen des Nelder-Mead-Verfahrens, um auch solche Probleme zu l\u00f6sen.",
            "title": "Nelder-Mead-Verfahren"
        },
        {
            "location": "/#abstiegsverfahren",
            "text": "Das Abstiegsverfahren ist ein weiteres Verfahren zur Optimierung einer Funktion. Ein Vektor d hei\u00dft Abstiegsrichtung von Funktion f in einem Punkt x, falls es ein T gibt, sodass gilt:  f (x + td) < f (x)  f\u00fcr jedes  0 < t < T . Dieser Vektor zeigt also in die Richtung, in welcher der Wert der Funktion in allen Punkten kleiner als T weniger als der Funktionswert bei x ist. Wir k\u00f6nnen auch sagen, dass wenn  \u2207f (x)T d < 0  gilt, dann ist d die Abstiegsrichtung von f im Punkt x. Um ein lokales Minimum mit dieser Methode zu finden, muss man zuerst die Abstiegsrichtung in einem beliebigen Startpunkt finden. Dann bewegt man sich zu dem Punkt, in dessen Richtung der Abstiegsvektor zeigt, und berechnet dort erneut den Abstiegsvektor. Man wiederholt dies, bis kein neuer Vektor berechnet werden kann oder die erforderliche Genauigkeit erreicht wurde.",
            "title": "Abstiegsverfahren"
        },
        {
            "location": "/#gradientenverfahren",
            "text": "Grunds\u00e4tzlich macht sich das Gradientenverfahren den Fakt zunutze, dass der Gradient immer in die Richtung des st\u00e4rksten Anstiegs zeigt. Dementsprechend zeigt nat\u00fcrlich der negative Gradient in die Richtung des st\u00e4rksten Abstiegs. Nun \u201egeht\u201c man eine gewisse Zeit in diese Richtung bis man einen neuen Punkt hat von dem man abermals den Gradienten ausrechnet. Die unterschiedlichen Gradientenverfahren unterscheiden sich nun darin wie weit man in die Richtung des negativen Gradienten gehen soll. Im theoretischen Teil wird sowohl st\u00e4rker auf das Gradientenverfahren an sich, als auch auf die Unterschiede zwischen den verschiedenen Arten eingegangen werden.",
            "title": "Gradientenverfahren"
        },
        {
            "location": "/#koordinatenabstiegsmethode",
            "text": "Bei der Koordinatenabstiegsmethode wird in jedem Schritt eine Koordinate i gew\u00e4hlt, nach der optimiert wird. Der Startpunkt ist beliebig w\u00e4hlbar und der folgende Vorgang wird mehrmals wiederholt. Bei jedem Durchgang werden alle Koordinaten des aktuellen Punktes x k in die Funktion eingesetzt, nur die gew\u00e4hlte Koordinate i beh\u00e4lt man als Variable bei. Die dadurch entstandene eindimensionale Funktion wird minimiert und die Koordinate i wird mit dem gefundenen Wert ersetzt. Dieser Vorgang wird mit allen Koordinaten wiederholt. Nun kann man diesen gesamten Vorgang erneut anwenden, bis sich der Punkt nicht mehr oder nur kaum ver\u00e4ndert; danach wird abgebrochen.",
            "title": "Koordinatenabstiegsmethode"
        }
    ]
}